{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint24-colab2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0UWxAno_mDLX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## [Task 3] Comparison among Several Datasets\n",
        "\n",
        "<br />\n",
        "\n",
        "I am going to use other datasets.\n",
        "\n",
        "\n",
        "https://keras.io/ja/datasets/#_5"
      ]
    },
    {
      "metadata": {
        "id": "l93dFV6_oBDD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Newswire of Reuters"
      ]
    },
    {
      "metadata": {
        "id": "2Z5DbhPullS0",
        "colab_type": "code",
        "outputId": "ac740468-5b9d-4ad4-e23c-0ca354e8065b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "\n",
        "from keras.datasets import reuters\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
        "                                                         num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=113,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 1s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AXZ9CwF0oSD2",
        "colab_type": "code",
        "outputId": "ea5edafb-ca7f-4b3b-c9de-2cd4e37816d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Build model...')\n",
        "lstm = Sequential()\n",
        "lstm.add(Embedding(max_features, 128))\n",
        "lstm.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "lstm.add(Dense(1, activation='softmax'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "lstm.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "lstm.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))\n",
        "lstm_score, lstm_acc = lstm.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', lstm_score)\n",
        "print('Test accuracy:', lstm_acc)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (8982, 80)\n",
            "x_test shape: (2246, 80)\n",
            "Build model...\n",
            "Train...\n",
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/15\n",
            "8982/8982 [==============================] - 45s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 2/15\n",
            "8982/8982 [==============================] - 44s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 3/15\n",
            "8982/8982 [==============================] - 44s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 4/15\n",
            "8982/8982 [==============================] - 43s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 5/15\n",
            "8982/8982 [==============================] - 44s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 6/15\n",
            "8982/8982 [==============================] - 43s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 7/15\n",
            "8982/8982 [==============================] - 44s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 8/15\n",
            "8982/8982 [==============================] - 43s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 9/15\n",
            "8982/8982 [==============================] - 43s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 10/15\n",
            "8982/8982 [==============================] - 43s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 11/15\n",
            "8982/8982 [==============================] - 44s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 12/15\n",
            "8982/8982 [==============================] - 44s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 13/15\n",
            "8982/8982 [==============================] - 44s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 14/15\n",
            "8982/8982 [==============================] - 44s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "Epoch 15/15\n",
            "8982/8982 [==============================] - 43s 5ms/step - loss: nan - acc: 0.0481 - val_loss: nan - val_acc: 0.0467\n",
            "2246/2246 [==============================] - 3s 1ms/step\n",
            "Test score: nan\n",
            "Test accuracy: 0.04674977738201247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VsNua5s3p9pQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}