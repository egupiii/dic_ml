{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of Natural Language Processing(NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from janome.tokenizer import Tokenizer\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.tokenfilter import *\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] Bag-of-Words(BoW) and N-gram\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to remove special characters such as ! and 〜, and split words, then quantify/vectorize the following corpus by BoW(1-gram) and BoW(2-gram)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: 今撮影中で〜す！\n",
    "\n",
    "\n",
    "2: 今休憩中で〜す(^^)\n",
    "\n",
    "\n",
    "3: 今日ドラマ撮影で〜す！\n",
    "\n",
    "\n",
    "4: 今日、映画瞬公開で〜す！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW(1-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "vocabulary = [\"I\", \"love\", \"this\", \"is\", \"the\", \"baseball\"]\n",
    "ms_kk_texts = [\"I love baseball !!\", \"I love this !\"]\n",
    "texts_vec = [[1,1,0,0,0,1], [1,1,1,0,0,0]]\n",
    "\n",
    "df_bow_1gram = pd.DataFrame(data=texts_vec, columns=vocabulary, index=ms_kk_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>love</th>\n",
       "      <th>this</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>baseball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I love baseball !!</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I love this !</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    I  love  this  is  the  baseball\n",
       "I love baseball !!  1     1     0   0    0         1\n",
       "I love this !       1     1     1   0    0         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow_1gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above four sentences\n",
    "\n",
    "voc_1g = [\"今\", \"撮影\", \"中\", \"です\", \"休憩\", \"今日\", \"ドラマ\", \"映画\", \"瞬\", \"公開\"]\n",
    "texts_1g = [\"今撮影中で〜す！\", \"今休憩中で〜す(^^)\", \"今日ドラマ撮影で〜す！\", \"今日、映画瞬公開で〜す！！！\"]\n",
    "vec_1g = [[1,1,1,1,0,0,0,0,0,0], [1,0,1,1,1,0,0,0,0,0], [0,1,0,1,0,1,1,0,0,0], [0,0,0,1,0,1,0,1,1,1]]\n",
    "\n",
    "df_bow_1g = pd.DataFrame(data=vec_1g, columns=voc_1g, index=texts_1g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>今</th>\n",
       "      <th>撮影</th>\n",
       "      <th>中</th>\n",
       "      <th>です</th>\n",
       "      <th>休憩</th>\n",
       "      <th>今日</th>\n",
       "      <th>ドラマ</th>\n",
       "      <th>映画</th>\n",
       "      <th>瞬</th>\n",
       "      <th>公開</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>今撮影中で〜す！</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今休憩中で〜す(^^)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日ドラマ撮影で〜す！</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日、映画瞬公開で〜す！！！</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                今  撮影  中  です  休憩  今日  ドラマ  映画  瞬  公開\n",
       "今撮影中で〜す！        1   1  1   1   0   0    0   0  0   0\n",
       "今休憩中で〜す(^^)     1   0  1   1   1   0    0   0  0   0\n",
       "今日ドラマ撮影で〜す！     0   1  0   1   0   1    1   0  0   0\n",
       "今日、映画瞬公開で〜す！！！  0   0  0   1   0   1    0   1  1   1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow_1g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW(2-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above four sentences\n",
    "\n",
    "voc_2g = [\"今撮影\", \"撮影中\", \"中です\", \"今休憩\", \"休憩中\", \"今日ドラマ\", \"ドラマ撮影\", \"撮影です\", \"今日映画\", \"映画瞬\", \"瞬公開\", \"公開です\"]\n",
    "texts_2g = [\"今撮影中で〜す！\", \"今休憩中で〜す(^^)\", \"今日ドラマ撮影で〜す！\", \"今日、映画瞬公開で〜す！！！\"]\n",
    "vec_2g = [[1,1,1,0,0,0,0,0,0,0,0,0], [0,0,1,1,1,0,0,0,0,0,0,0], [0,0,0,0,0,1,1,1,0,0,0,0], [0,0,0,0,0,0,0,0,1,1,1,1]]\n",
    "\n",
    "df_bow_2g = pd.DataFrame(data=vec_2g, columns=voc_2g, index=texts_2g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>今撮影</th>\n",
       "      <th>撮影中</th>\n",
       "      <th>中です</th>\n",
       "      <th>今休憩</th>\n",
       "      <th>休憩中</th>\n",
       "      <th>今日ドラマ</th>\n",
       "      <th>ドラマ撮影</th>\n",
       "      <th>撮影です</th>\n",
       "      <th>今日映画</th>\n",
       "      <th>映画瞬</th>\n",
       "      <th>瞬公開</th>\n",
       "      <th>公開です</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>今撮影中で〜す！</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今休憩中で〜す(^^)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日ドラマ撮影で〜す！</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日、映画瞬公開で〜す！！！</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                今撮影  撮影中  中です  今休憩  休憩中  今日ドラマ  ドラマ撮影  撮影です  今日映画  映画瞬  瞬公開  \\\n",
       "今撮影中で〜す！          1    1    1    0    0      0      0     0     0    0    0   \n",
       "今休憩中で〜す(^^)       0    0    1    1    1      0      0     0     0    0    0   \n",
       "今日ドラマ撮影で〜す！       0    0    0    0    0      1      1     1     0    0    0   \n",
       "今日、映画瞬公開で〜す！！！    0    0    0    0    0      0      0     0     1    1    1   \n",
       "\n",
       "                公開です  \n",
       "今撮影中で〜す！           0  \n",
       "今休憩中で〜す(^^)        0  \n",
       "今日ドラマ撮影で〜す！        0  \n",
       "今日、映画瞬公開で〜す！！！     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow_2g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] TF-IDF\n",
    "\n",
    "<br />\n",
    "\n",
    "I will quantify/vectorize the corpus of the 1st task by TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Formula of TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency(TF):\n",
    "\n",
    "$$\n",
    "tf(t,d) = \\frac{n_{t,d}}{\\sum_{s \\in d}n_{s,d}}\n",
    "$$\n",
    "\n",
    "$n_{t,d}$ : Number of words \"t\" on a document \"d\"\n",
    "\n",
    "$\\sum_{s \\in d}n_{s,d}$ : Sum of number of all words on a document \"d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Document Frequency(IDF):\n",
    "\n",
    "$$\n",
    "idf(t) = \\log{\\frac{N}{df(t)}}\n",
    "$$\n",
    "\n",
    "$N$ : Number of all documents\n",
    "\n",
    "$df(t)$ : Number of documents that a word \"t\" appears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF:\n",
    "\n",
    "$$\n",
    "tfidf(t, d) = tf(t, d) \\times idf(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above four sentences\n",
    "\n",
    "original_texts = [\"今撮影中で〜す！\", \"今休憩中で〜す(^^)\", \"今日ドラマ撮影で〜す！\", \"今日、映画瞬公開で〜す！！！\"]\n",
    "\n",
    "voc_tf_idf = [\"今\", \"撮影\", \"中\", \"です\", \"休憩\", \"今日\", \"ドラマ\", \"映画\", \"瞬\", \"公開\"]\n",
    "texts_tf_idf = [\"今撮影中です\", \"今休憩中です\", \"今日ドラマ撮影です\", \"今日映画瞬公開です\"]\n",
    "vec_tf_idf = [[1,1,1,1,0,0,0,0,0,0], [1,0,1,1,1,0,0,0,0,0], [0,1,0,1,0,1,1,0,0,0], [0,0,0,1,0,1,0,1,1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF\n",
    "\n",
    "tf_list = []\n",
    "for i in range(len(texts_tf_idf)):\n",
    "    tf = []\n",
    "    for j in range(len(voc_tf_idf)):\n",
    "        tf.append(texts_tf_idf[i].count(voc_tf_idf[j]) / vec_tf_idf[i].count(1))\n",
    "    tf_list.append(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.25, 0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.25, 0.0, 0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.25, 0.25, 0.0, 0.25, 0.0, 0.25, 0.25, 0.0, 0.0, 0.0],\n",
       " [0.2, 0.0, 0.0, 0.2, 0.0, 0.2, 0.0, 0.2, 0.2, 0.2]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IDF\n",
    "\n",
    "idf_list = []\n",
    "for j in range(len(vec_tf_idf[0])):\n",
    "    count = 0\n",
    "    for i in range(len(texts_tf_idf)):\n",
    "        if vec_tf_idf[i][j] == 1:\n",
    "            count += 1\n",
    "    idf = math.log2(len(texts_tf_idf) / count)\n",
    "    idf_list.append(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF\n",
    "\n",
    "tf_idf_list = []\n",
    "for i in range(len(tf_list)):\n",
    "    tf_idf = []\n",
    "    for j in range(len(idf_list)):\n",
    "        tf_idf.append(tf_list[i][j] * idf_list[j])\n",
    "    tf_idf_list.append(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.25, 0.0, 0.25, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.25, 0.25, 0.0, 0.0, 0.0, 0.25, 0.5, 0.0, 0.0, 0.0],\n",
       " [0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.4, 0.4, 0.4]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "\n",
    "df_tf_idf = pd.DataFrame(data=tf_idf_list, columns=voc_tf_idf, index=original_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>今</th>\n",
       "      <th>撮影</th>\n",
       "      <th>中</th>\n",
       "      <th>です</th>\n",
       "      <th>休憩</th>\n",
       "      <th>今日</th>\n",
       "      <th>ドラマ</th>\n",
       "      <th>映画</th>\n",
       "      <th>瞬</th>\n",
       "      <th>公開</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>今撮影中で〜す！</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今休憩中で〜す(^^)</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日ドラマ撮影で〜す！</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>今日、映画瞬公開で〜す！！！</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   今    撮影     中   です   休憩    今日  ドラマ   映画    瞬   公開\n",
       "今撮影中で〜す！        0.25  0.25  0.25  0.0  0.0  0.00  0.0  0.0  0.0  0.0\n",
       "今休憩中で〜す(^^)     0.25  0.00  0.25  0.0  0.5  0.00  0.0  0.0  0.0  0.0\n",
       "今日ドラマ撮影で〜す！     0.25  0.25  0.00  0.0  0.0  0.25  0.5  0.0  0.0  0.0\n",
       "今日、映画瞬公開で〜す！！！  0.20  0.00  0.00  0.0  0.0  0.20  0.0  0.4  0.4  0.4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 3] Text Cleaning\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to remove urls, 【◯◯】, special characters including line breaks and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "text = \"<!everyone> *【スペシャル特典】有償のRubyMineやPyCharmの `6ヶ月間100%OFFクーポン` をご希望者の方先着100名様に贈呈いたします！*\\n\\nこの度、RubyMineやPyCharmのメーカーであるJetBrains社へのクーポンコードの提供交渉が実り、100クーポンをいただくことができました。\\n\\n```\\nRubyMine\\n<https://www.jetbrains.com/ruby/>\\n\\nPyCharm\\n<https://www.jetbrains.com/pycharm/>\\n```\\n\\n「ご希望の方は、手を挙げて！」方式で、ご希望の方はこの投稿の手あげスタンプをクリックしてください。\\n\\n期限は、 *`2019年3月20日（水）22:00まで`* とさせていただきます。\\nふるってのご希望をお待ちしております！ :smile:\"\n",
    "\n",
    "# <◯◯>\n",
    "text = re.sub(r\"<(.+)>\", \"\", text)\n",
    "# 【◯◯】\n",
    "text = re.sub(r\"【(.+)】\", \"\", text)\n",
    "# Urls\n",
    "text = re.sub(r\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+\", \"\", text)\n",
    "# Emojis\n",
    "text = re.sub(r\":([a-xA-Z0-9_]+):\", \"\", text)\n",
    "# Special characters\n",
    "text = re.sub(r\"[\\n\\*`\\s]\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'有償のRubyMineやPyCharmの6ヶ月間100%OFFクーポンをご希望者の方先着100名様に贈呈いたします！この度、RubyMineやPyCharmのメーカーであるJetBrains社へのクーポンコードの提供交渉が実り、100クーポンをいただくことができました。RubyMinePyCharm「ご希望の方は、手を挙げて！」方式で、ご希望の方はこの投稿の手あげスタンプをクリックしてください。期限は、2019年3月20日（水）22:00までとさせていただきます。ふるってのご希望をお待ちしております！'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "correct_text = \"有償のRubyMineやPyCharmの6ヶ月間100%OFFクーポンをご希望者の方先着100名様に贈呈いたします！この度、RubyMineやPyCharmのメーカーであるJetBrains社へのクーポンコードの提供交渉が実り、100クーポンをいただくことができました。RubyMinePyCharm「ご希望の方は、手を挙げて！」方式で、ご希望の方はこの投稿の手あげスタンプをクリックしてください。期限は、2019年3月20日（水）22:00までとさせていただきます。ふるってのご希望をお待ちしております！\"\n",
    "\n",
    "text == correct_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 4] Morphological Analysis\n",
    "\n",
    "<br />\n",
    "\n",
    "There are tools for morphological analysis, like Mecab and Janome. In this task, I will use Janome.\n",
    "\n",
    "\n",
    "https://mocobeta.github.io/janome/\n",
    "\n",
    "<br />\n",
    "\n",
    "I will do morphological analysis about the text that I did text cleaning on the previous task to extract nouns and verbs by Janome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有償\t名詞,一般,*,*,*,*,有償,ユウショウ,ユーショー\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "RubyMine\t名詞,一般,*,*,*,*,RubyMine,*,*\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "PyCharm\t名詞,一般,*,*,*,*,PyCharm,*,*\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "6\t名詞,数,*,*,*,*,6,*,*\n",
      "ヶ月\t名詞,接尾,助数詞,*,*,*,ヶ月,カゲツ,カゲツ\n",
      "間\t名詞,接尾,一般,*,*,*,間,カン,カン\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "%\t名詞,サ変接続,*,*,*,*,%,*,*\n",
      "OFF\t名詞,一般,*,*,*,*,OFF,*,*\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "ご\t接頭詞,名詞接続,*,*,*,*,ご,ゴ,ゴ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "者\t名詞,接尾,一般,*,*,*,者,シャ,シャ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "先着\t名詞,サ変接続,*,*,*,*,先着,センチャク,センチャク\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "名\t名詞,接尾,助数詞,*,*,*,名,メイ,メイ\n",
      "様\t名詞,接尾,人名,*,*,*,様,サマ,サマ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "贈呈\t名詞,サ変接続,*,*,*,*,贈呈,ゾウテイ,ゾーテイ\n",
      "いたし\t動詞,非自立,*,*,五段・サ行,連用形,いたす,イタシ,イタシ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n",
      "この\t連体詞,*,*,*,*,*,この,コノ,コノ\n",
      "度\t名詞,非自立,副詞可能,*,*,*,度,タビ,タビ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "RubyMine\t名詞,固有名詞,組織,*,*,*,RubyMine,*,*\n",
      "や\t助詞,並立助詞,*,*,*,*,や,ヤ,ヤ\n",
      "PyCharm\t名詞,一般,*,*,*,*,PyCharm,*,*\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "メーカー\t名詞,一般,*,*,*,*,メーカー,メーカー,メーカー\n",
      "で\t助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\n",
      "ある\t助動詞,*,*,*,五段・ラ行アル,基本形,ある,アル,アル\n",
      "JetBrains\t名詞,一般,*,*,*,*,JetBrains,*,*\n",
      "社\t名詞,接尾,一般,*,*,*,社,シャ,シャ\n",
      "へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "コード\t名詞,一般,*,*,*,*,コード,コード,コード\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "提供\t名詞,サ変接続,*,*,*,*,提供,テイキョウ,テイキョー\n",
      "交渉\t名詞,サ変接続,*,*,*,*,交渉,コウショウ,コーショー\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "実り\t動詞,自立,*,*,五段・ラ行,連用形,実る,ミノリ,ミノリ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "いただく\t動詞,自立,*,*,五段・カ行イ音便,基本形,いただく,イタダク,イタダク\n",
      "こと\t名詞,非自立,一般,*,*,*,こと,コト,コト\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "でき\t動詞,自立,*,*,一段,連用形,できる,デキ,デキ\n",
      "まし\t助動詞,*,*,*,特殊・マス,連用形,ます,マシ,マシ\n",
      "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "RubyMinePyCharm\t名詞,一般,*,*,*,*,RubyMinePyCharm,*,*\n",
      "「\t記号,括弧開,*,*,*,*,「,「,「\n",
      "ご\t接頭詞,名詞接続,*,*,*,*,ご,ゴ,ゴ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "手\t名詞,一般,*,*,*,*,手,テ,テ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "挙げ\t動詞,自立,*,*,一段,連用形,挙げる,アゲ,アゲ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n",
      "」\t記号,括弧閉,*,*,*,*,」,」,」\n",
      "方式\t名詞,一般,*,*,*,*,方式,ホウシキ,ホーシキ\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "ご\t接頭詞,名詞接続,*,*,*,*,ご,ゴ,ゴ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "この\t連体詞,*,*,*,*,*,この,コノ,コノ\n",
      "投稿\t名詞,サ変接続,*,*,*,*,投稿,トウコウ,トーコー\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "手\t名詞,一般,*,*,*,*,手,テ,テ\n",
      "あげ\t動詞,自立,*,*,一段,連用形,あげる,アゲ,アゲ\n",
      "スタンプ\t名詞,一般,*,*,*,*,スタンプ,スタンプ,スタンプ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "クリック\t名詞,一般,*,*,*,*,クリック,クリック,クリック\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "ください\t動詞,非自立,*,*,五段・ラ行特殊,命令ｉ,くださる,クダサイ,クダサイ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "期限\t名詞,一般,*,*,*,*,期限,キゲン,キゲン\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "2019\t名詞,数,*,*,*,*,2019,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "3\t名詞,数,*,*,*,*,3,*,*\n",
      "月\t名詞,一般,*,*,*,*,月,ツキ,ツキ\n",
      "20\t名詞,数,*,*,*,*,20,*,*\n",
      "日\t名詞,接尾,助数詞,*,*,*,日,ニチ,ニチ\n",
      "（\t記号,括弧開,*,*,*,*,（,（,（\n",
      "水\t名詞,一般,*,*,*,*,水,ミズ,ミズ\n",
      "）\t記号,括弧閉,*,*,*,*,）,）,）\n",
      "22\t名詞,数,*,*,*,*,22,*,*\n",
      ":\t名詞,サ変接続,*,*,*,*,:,*,*\n",
      "00\t名詞,数,*,*,*,*,00,*,*\n",
      "まで\t助詞,副助詞,*,*,*,*,まで,マデ,マデ\n",
      "と\t助詞,格助詞,引用,*,*,*,と,ト,ト\n",
      "さ\t動詞,自立,*,*,サ変・スル,未然レル接続,する,サ,サ\n",
      "せ\t動詞,接尾,*,*,一段,連用形,せる,セ,セ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "いただき\t動詞,非自立,*,*,五段・カ行イ音便,連用形,いただく,イタダキ,イタダキ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "ふるって\t副詞,一般,*,*,*,*,ふるって,フルッテ,フルッテ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "ご\t接頭詞,名詞接続,*,*,*,*,ご,ゴ,ゴ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "お待ち\t名詞,サ変接続,*,*,*,*,お待ち,オマチ,オマチ\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "おり\t動詞,非自立,*,*,五段・ラ行,連用形,おる,オリ,オリ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "for token in t.tokenize(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有償\t名詞,一般,*,*,*,*,有償,ユウショウ,ユーショー\n",
      "RubyMine\t名詞,一般,*,*,*,*,RubyMine,*,*\n",
      "PyCharm\t名詞,一般,*,*,*,*,PyCharm,*,*\n",
      "6\t名詞,数,*,*,*,*,6,*,*\n",
      "ヶ月\t名詞,接尾,助数詞,*,*,*,ヶ月,カゲツ,カゲツ\n",
      "間\t名詞,接尾,一般,*,*,*,間,カン,カン\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "%\t名詞,サ変接続,*,*,*,*,%,*,*\n",
      "OFF\t名詞,一般,*,*,*,*,OFF,*,*\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "者\t名詞,接尾,一般,*,*,*,者,シャ,シャ\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "先着\t名詞,サ変接続,*,*,*,*,先着,センチャク,センチャク\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "名\t名詞,接尾,助数詞,*,*,*,名,メイ,メイ\n",
      "様\t名詞,接尾,人名,*,*,*,様,サマ,サマ\n",
      "贈呈\t名詞,サ変接続,*,*,*,*,贈呈,ゾウテイ,ゾーテイ\n",
      "度\t名詞,非自立,副詞可能,*,*,*,度,タビ,タビ\n",
      "RubyMine\t名詞,固有名詞,組織,*,*,*,RubyMine,*,*\n",
      "PyCharm\t名詞,一般,*,*,*,*,PyCharm,*,*\n",
      "メーカー\t名詞,一般,*,*,*,*,メーカー,メーカー,メーカー\n",
      "JetBrains\t名詞,一般,*,*,*,*,JetBrains,*,*\n",
      "社\t名詞,接尾,一般,*,*,*,社,シャ,シャ\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "コード\t名詞,一般,*,*,*,*,コード,コード,コード\n",
      "提供\t名詞,サ変接続,*,*,*,*,提供,テイキョウ,テイキョー\n",
      "交渉\t名詞,サ変接続,*,*,*,*,交渉,コウショウ,コーショー\n",
      "100\t名詞,数,*,*,*,*,100,*,*\n",
      "クーポン\t名詞,一般,*,*,*,*,クーポン,クーポン,クーポン\n",
      "こと\t名詞,非自立,一般,*,*,*,こと,コト,コト\n",
      "RubyMinePyCharm\t名詞,一般,*,*,*,*,RubyMinePyCharm,*,*\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "手\t名詞,一般,*,*,*,*,手,テ,テ\n",
      "方式\t名詞,一般,*,*,*,*,方式,ホウシキ,ホーシキ\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "方\t名詞,非自立,一般,*,*,*,方,ホウ,ホー\n",
      "投稿\t名詞,サ変接続,*,*,*,*,投稿,トウコウ,トーコー\n",
      "手\t名詞,一般,*,*,*,*,手,テ,テ\n",
      "スタンプ\t名詞,一般,*,*,*,*,スタンプ,スタンプ,スタンプ\n",
      "クリック\t名詞,一般,*,*,*,*,クリック,クリック,クリック\n",
      "期限\t名詞,一般,*,*,*,*,期限,キゲン,キゲン\n",
      "2019\t名詞,数,*,*,*,*,2019,*,*\n",
      "年\t名詞,接尾,助数詞,*,*,*,年,ネン,ネン\n",
      "3\t名詞,数,*,*,*,*,3,*,*\n",
      "月\t名詞,一般,*,*,*,*,月,ツキ,ツキ\n",
      "20\t名詞,数,*,*,*,*,20,*,*\n",
      "日\t名詞,接尾,助数詞,*,*,*,日,ニチ,ニチ\n",
      "水\t名詞,一般,*,*,*,*,水,ミズ,ミズ\n",
      "22\t名詞,数,*,*,*,*,22,*,*\n",
      ":\t名詞,サ変接続,*,*,*,*,:,*,*\n",
      "00\t名詞,数,*,*,*,*,00,*,*\n",
      "希望\t名詞,サ変接続,*,*,*,*,希望,キボウ,キボー\n",
      "お待ち\t名詞,サ変接続,*,*,*,*,お待ち,オマチ,オマチ\n"
     ]
    }
   ],
   "source": [
    "# Nouns\n",
    "\n",
    "token_filters = [POSKeepFilter(\"名詞\")]\n",
    "a = Analyzer(token_filters=token_filters)\n",
    "for token in a.analyze(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "いたし\t動詞,非自立,*,*,五段・サ行,連用形,いたす,イタシ,イタシ\n",
      "実り\t動詞,自立,*,*,五段・ラ行,連用形,実る,ミノリ,ミノリ\n",
      "いただく\t動詞,自立,*,*,五段・カ行イ音便,基本形,いただく,イタダク,イタダク\n",
      "でき\t動詞,自立,*,*,一段,連用形,できる,デキ,デキ\n",
      "挙げ\t動詞,自立,*,*,一段,連用形,挙げる,アゲ,アゲ\n",
      "あげ\t動詞,自立,*,*,一段,連用形,あげる,アゲ,アゲ\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "ください\t動詞,非自立,*,*,五段・ラ行特殊,命令ｉ,くださる,クダサイ,クダサイ\n",
      "さ\t動詞,自立,*,*,サ変・スル,未然レル接続,する,サ,サ\n",
      "せ\t動詞,接尾,*,*,一段,連用形,せる,セ,セ\n",
      "いただき\t動詞,非自立,*,*,五段・カ行イ音便,連用形,いただく,イタダキ,イタダキ\n",
      "し\t動詞,自立,*,*,サ変・スル,連用形,する,シ,シ\n",
      "おり\t動詞,非自立,*,*,五段・ラ行,連用形,おる,オリ,オリ\n"
     ]
    }
   ],
   "source": [
    "# Verbs\n",
    "\n",
    "token_filters = [POSKeepFilter(\"動詞\")]\n",
    "a = Analyzer(token_filters=token_filters)\n",
    "for token in a.analyze(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 5] Analyze News\n",
    "\n",
    "<br />\n",
    "\n",
    "I will analyze some news of \"livedoor\" from various viewpoints.\n",
    "\n",
    "\n",
    "http://news.livedoor.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "livedoor ニュースコーパス\r\n",
      "\r\n",
      "\r\n",
      "概要\r\n",
      "-----------------\r\n",
      "本コーパスは、NHN Japan株式会社が運営する「livedoor ニュース」のうち、下記のクリエイティブ・コモンズ\r\n",
      "ライセンスが適用されるニュース記事を収集し、可能な限りHTMLタグを取り除いて作成したものです。\r\n",
      "\r\n",
      "- トピックニュース\r\n",
      "  http://news.livedoor.com/category/vender/news/\r\n",
      "- Sports Watch\r\n",
      "  http://news.livedoor.com/category/vender/208/\r\n",
      "- ITライフハック\r\n",
      "  http://news.livedoor.com/category/vender/223/\r\n",
      "- 家電チャンネル\r\n",
      "  http://news.livedoor.com/category/vender/kadench/\r\n",
      "- MOVIE ENTER\r\n",
      "  http://news.livedoor.com/category/vender/movie_enter/\r\n",
      "- 独女通信\r\n",
      "  http://news.livedoor.com/category/vender/90/\r\n",
      "- エスマックス\r\n",
      "  http://news.livedoor.com/category/vender/smax/\r\n",
      "- livedoor HOMME\r\n",
      "  http://news.livedoor.com/category/vender/homme/\r\n",
      "- Peachy\r\n",
      "  http://news.livedoor.com/category/vender/ldgirls/\r\n",
      "\r\n",
      "収集時期：2012年9月上旬\r\n",
      "\r\n",
      "\r\n",
      "ライセンス\r\n",
      "-----------------\r\n",
      "各記事ファイルにはクリエイティブ・コモンズライセンス「表示 - 改変禁止」\r\n",
      "（http://creativecommons.org/licenses/by-nd/2.1/jp/）が適用されます。\r\n",
      "クレジット表示についてはニュースカテゴリにより異なるため、サブディレクトリにある\r\n",
      "それぞれの LICENSE.txt をご覧ください。\r\n",
      "\r\n",
      "livedoor はNHN Japan株式会社の登録商標です。\r\n",
      "\r\n",
      "\r\n",
      "記事ファイルのフォーマット\r\n",
      "-----------------\r\n",
      "記事ファイルは以下のフォーマットにしたがって作成されています：\r\n",
      "\r\n",
      "１行目：記事のURL\r\n",
      "２行目：記事の日付\r\n",
      "３行目：記事のタイトル\r\n",
      "４行目以降：記事の本文\r\n",
      "\r\n",
      "\r\n",
      "管理者／連絡先\r\n",
      "-----------------\r\n",
      "本コーパスに関するお問い合わせは、記事を収集した下記会社宛にお願いいたします：\r\n",
      "\r\n",
      "株式会社ロンウイット\r\n",
      "http://www.rondhuit.com/\r\n",
      "メール：sales@rondhuit.com\r\n",
      "\r\n",
      "\r\n",
      "謝辞\r\n",
      "-----------------\r\n",
      "「livedoor ニュース」の一部をクリエイティブ・コモンズライセンスのもと公開してくださいました\r\n",
      "NHN Japan株式会社様に感謝いたします。\r\n"
     ]
    }
   ],
   "source": [
    "# Show an explanation of the \"livedoor\" news\n",
    "\n",
    "cat text/README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "bin_data = load_files('./text', encoding='utf-8')\n",
    "\n",
    "documents = bin_data.data\n",
    "\n",
    "# Get labels while will not use them this time.\n",
    "targets = bin_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.livedoor.com/article/detail/4931238/\n",
      "2010-08-08T10:00:00+0900\n",
      "NY名物イベントが日本でも！名店グルメを気軽に楽しむ\n",
      "ニューヨークで20年続いている食の祭典「レストラン・ウィーク」。その日本版がダイナーズクラブ特別協賛のもと7月30日よりスタート。8月31日までの期間中、青山・六本木、丸の内、銀座、横浜のエリアから、ラグジュアリーレストラン81店舗がこのイベントのために特別用意したランチメニュー2010円（税・サ別）、ディナー5000円（税・サ別）を気軽に楽しめる、とっておきのイベントです。\n",
      "　\n",
      "　実行委員長には、学校法人服部学園、服部栄養専門学校 理事長・校長であり医学博士でもある服部幸應氏を迎え、実行委員に石田純一さん、LA BETTOLAオーナーシェフ落合務氏、フードアナリスト協会会長、高賀右近氏、つきぢ田村三代目、田村隆氏に、そして放送作家・脚本家の小山薫堂さんなど、食のスペシャリストたちが勢揃い。\n",
      "\n",
      "参加レストランには、ミシュランのフランス版、東京版ともに星を獲得している吉野建シェフの「レストラン タテル ヨシノ 汐留」や、日本料理の名門「つきぢ田村」、「金田中 庵」、「赤坂璃宮」に「mikuni MARUNOUCHI」など、日本を代表するレストランがずらり。\n",
      "　イベント期間の〜8月19日までは、特別協賛のダイナーズクラブカード会員、またはシティバンクに口座を持つシティゴールドメンバーが楽しめる先行期間となりますが、その後は誰でも参加できるので、日程のチェックは必須。\n",
      "\n",
      "　予約方法は必ず事前に、各店舗に問合せを行い「ジャパンレストラン・ウィーク2010」での予約であることを伝えればOK！憧れていたレストランの料理をリーズナブルにいただけるチャンスです！極上の味とラグジュアリーな空間を満喫。そんな幸せを実感できる「ジャパンレストラン・ウィーク2010」にぜひ参加しててみてはいかがですか？\n",
      "\n",
      "JAPAN RESTAURANT WEEK 2010 -公式サイト\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://news.livedoor.com/article/detail/4931238/\\n2010-08-08T10:00:00+0900\\nNY名物イベントが日本でも！名店グルメを気軽に楽しむ\\nニューヨークで20年続いている食の祭典「レストラン・ウィーク」。その日本版がダイナーズクラブ特別協賛のもと7月30日よりスタート。8月31日までの期間中、青山・六本木、丸の内、銀座、横浜のエリアから、ラグジュアリーレストラン81店舗がこのイベントのために特別用意したランチメニュー2010円（税・サ別）、ディナー5000円（税・サ別）を気軽に楽しめる、とっておきのイベントです。\\n\\u3000\\n\\u3000実行委員長には、学校法人服部学園、服部栄養専門学校 理事長・校長であり医学博士でもある服部幸應氏を迎え、実行委員に石田純一さん、LA BETTOLAオーナーシェフ落合務氏、フードアナリスト協会会長、高賀右近氏、つきぢ田村三代目、田村隆氏に、そして放送作家・脚本家の小山薫堂さんなど、食のスペシャリストたちが勢揃い。\\n\\n参加レストランには、ミシュランのフランス版、東京版ともに星を獲得している吉野建シェフの「レストラン タテル ヨシノ 汐留」や、日本料理の名門「つきぢ田村」、「金田中 庵」、「赤坂璃宮」に「mikuni MARUNOUCHI」など、日本を代表するレストランがずらり。\\n\\u3000イベント期間の〜8月19日までは、特別協賛のダイナーズクラブカード会員、またはシティバンクに口座を持つシティゴールドメンバーが楽しめる先行期間となりますが、その後は誰でも参加できるので、日程のチェックは必須。\\n\\n\\u3000予約方法は必ず事前に、各店舗に問合せを行い「ジャパンレストラン・ウィーク2010」での予約であることを伝えればOK！憧れていたレストランの料理をリーズナブルにいただけるチャンスです！極上の味とラグジュアリーな空間を満喫。そんな幸せを実感できる「ジャパンレストラン・ウィーク2010」にぜひ参加しててみてはいかがですか？\\n\\nJAPAN RESTAURANT WEEK 2010 -公式サイト\\n'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 8, 7, ..., 1, 3, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze News by Counting Vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_filters1 = [TokenCountFilter()]\n",
    "a1 = Analyzer(token_filters=token_filters1)\n",
    "dic = {}\n",
    "for doc in documents:\n",
    "    for k, v in a1.analyze(doc):\n",
    "        if k not in dic:\n",
    "            dic[k] = v\n",
    "        else:\n",
    "            dic[k] += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Heavy to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort\n",
    "\n",
    "dic_sorted = sorted(dic.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_sorted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Heavy to show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = []\n",
    "for doc in documents:\n",
    "    # Remove urls\n",
    "    BAD_SYMBOL = re.compile(r\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+\")\n",
    "    doc = re.sub(BAD_SYMBOL, \"\", doc)\n",
    "    \n",
    "    # Remove dates\n",
    "    BAD_SYMBOL = re.compile(r\"\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\+\\d{4}\")\n",
    "    doc = re.sub(BAD_SYMBOL, \"\", doc)\n",
    "    \n",
    "    # Remove special characters\n",
    "    BAD_SYMBOL = re.compile(r\"[\\n\\*`\\s:：「」、,。\\.・/／\\-\\(\\)（）!！『』？\\?【】”“■\\+＋〜~※&＆×％|●◯＜＞＝=★→]+\")\n",
    "    doc = re.sub(BAD_SYMBOL, \"\", doc)\n",
    "    \n",
    "    # Replace all numbers to \"NUMBER\"\n",
    "    BAD_SYMBOL = re.compile(r\"\\d+\")\n",
    "    doc = re.sub(BAD_SYMBOL, \"NUMBER\", doc)\n",
    "    \n",
    "    doc_clean.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NY名物イベントが日本でも名店グルメを気軽に楽しむニューヨークでNUMBER年続いている食の祭典レストランウィークその日本版がダイナーズクラブ特別協賛のもとNUMBER月NUMBER日よりスタートNUMBER月NUMBER日までの期間中青山六本木丸の内銀座横浜のエリアからラグジュアリーレストランNUMBER店舗がこのイベントのために特別用意したランチメニューNUMBER円税サ別ディナーNUMBER円税サ別を気軽に楽しめるとっておきのイベントです実行委員長には学校法人服部学園服部栄養専門学校理事長校長であり医学博士でもある服部幸應氏を迎え実行委員に石田純一さんLABETTOLAオーナーシェフ落合務氏フードアナリスト協会会長高賀右近氏つきぢ田村三代目田村隆氏にそして放送作家脚本家の小山薫堂さんなど食のスペシャリストたちが勢揃い参加レストランにはミシュランのフランス版東京版ともに星を獲得している吉野建シェフのレストランタテルヨシノ汐留や日本料理の名門つきぢ田村金田中庵赤坂璃宮にmikuniMARUNOUCHIなど日本を代表するレストランがずらりイベント期間のNUMBER月NUMBER日までは特別協賛のダイナーズクラブカード会員またはシティバンクに口座を持つシティゴールドメンバーが楽しめる先行期間となりますがその後は誰でも参加できるので日程のチェックは必須予約方法は必ず事前に各店舗に問合せを行いジャパンレストランウィークNUMBERでの予約であることを伝えればOK憧れていたレストランの料理をリーズナブルにいただけるチャンスです極上の味とラグジュアリーな空間を満喫そんな幸せを実感できるジャパンレストランウィークNUMBERにぜひ参加しててみてはいかがですかJAPANRESTAURANTWEEKNUMBER公式サイト'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize by BoW and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW (1-gram)\n",
    "\n",
    "# Split documents into each word\n",
    "t_wakati = Tokenizer(wakati=True)\n",
    "\n",
    "news_voc = []\n",
    "for doc in doc_clean:\n",
    "    voc = t_wakati.tokenize(doc)\n",
    "    news_voc.append(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NY'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "news_voc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite all lists to a single list\n",
    "\n",
    "united_voc = []\n",
    "for i in range(len(news_voc)):\n",
    "    for j in range(len(news_voc[i])):\n",
    "        united_voc.append(news_voc[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NY', '名物', 'イベント', 'が', '日本', 'で', 'も', '名店', 'グルメ', 'を']\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "print(united_voc[:10])\n",
    "print(united_voc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c6a704bd0fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munited_voc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mnews_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a list of vectors\n",
    "\n",
    "news_vec = [[] for i in range(len(doc_clean))]\n",
    "\n",
    "for i in range(len(doc_clean)):\n",
    "    for voc in united_voc:\n",
    "        if voc in doc_clean[i]:\n",
    "            news_vec[i].append(1)\n",
    "        else:\n",
    "            news_vec[i].append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - The processing wasted too much time, so I gave up completing it and running the following 3 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Check\n",
    "\n",
    "# news_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data a dataframe\n",
    "\n",
    "# df_news_bow = pd.DataFrame(data=news_vec, columns=united_voc, index=doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "\n",
    "# df_news_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "\n",
    "space_doc = []\n",
    "for i in range(len(news_voc)):\n",
    "    doc = \"\"\n",
    "    for j in range(len(news_voc[i])):\n",
    "        doc += news_voc[i][j] + \" \"\n",
    "    space_doc.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit\n",
    "X = vectorizer.fit_transform(space_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8507"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show index\n",
    "\n",
    "vectorizer.vocabulary_[\"ny\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TF-IDF values\n",
    "\n",
    "tf_idf_array = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "tf_idf_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.362136716343215"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(tf_idf_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Not 0, so it seems like the processing worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a definition to output a piece of news whose cosine similarity has the highest correlation with a piece of news selected\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "\n",
    "\n",
    "def closest_cos_sim(X, y):\n",
    "    \"\"\"\n",
    "    X : All news except for y\n",
    "    y : Single news selected\n",
    "    \"\"\"\n",
    "    \n",
    "    cos_similarity = 0\n",
    "    index = -1\n",
    "    for i in range(len(X)):\n",
    "        a = cos_sim(X[i], y)\n",
    "        if a == 1:\n",
    "            pass\n",
    "        elif a > cos_similarity:\n",
    "            cos_similarity = a\n",
    "            index = i\n",
    "        else:\n",
    "            pass\n",
    "    return cos_similarity, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the definition\n",
    "\n",
    "cos_sim1, index1 = closest_cos_sim(tf_idf_array, tf_idf_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1617431820331787\n",
      "3548\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim1)\n",
    "print(index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.livedoor.com/article/detail/4931238/\n",
      "2010-08-08T10:00:00+0900\n",
      "NY名物イベントが日本でも！名店グルメを気軽に楽しむ\n",
      "ニューヨークで20年続いている食の祭典「レストラン・ウィーク」。その日本版がダイナーズクラブ特別協賛のもと7月30日よりスタート。8月31日までの期間中、青山・六本木、丸の内、銀座、横浜のエリアから、ラグジュアリーレストラン81店舗がこのイベントのために特別用意したランチメニュー2010円（税・サ別）、ディナー5000円（税・サ別）を気軽に楽しめる、とっておきのイベントです。\n",
      "　\n",
      "　実行委員長には、学校法人服部学園、服部栄養専門学校 理事長・校長であり医学博士でもある服部幸應氏を迎え、実行委員に石田純一さん、LA BETTOLAオーナーシェフ落合務氏、フードアナリスト協会会長、高賀右近氏、つきぢ田村三代目、田村隆氏に、そして放送作家・脚本家の小山薫堂さんなど、食のスペシャリストたちが勢揃い。\n",
      "\n",
      "参加レストランには、ミシュランのフランス版、東京版ともに星を獲得している吉野建シェフの「レストラン タテル ヨシノ 汐留」や、日本料理の名門「つきぢ田村」、「金田中 庵」、「赤坂璃宮」に「mikuni MARUNOUCHI」など、日本を代表するレストランがずらり。\n",
      "　イベント期間の〜8月19日までは、特別協賛のダイナーズクラブカード会員、またはシティバンクに口座を持つシティゴールドメンバーが楽しめる先行期間となりますが、その後は誰でも参加できるので、日程のチェックは必須。\n",
      "\n",
      "　予約方法は必ず事前に、各店舗に問合せを行い「ジャパンレストラン・ウィーク2010」での予約であることを伝えればOK！憧れていたレストランの料理をリーズナブルにいただけるチャンスです！極上の味とラグジュアリーな空間を満喫。そんな幸せを実感できる「ジャパンレストラン・ウィーク2010」にぜひ参加しててみてはいかがですか？\n",
      "\n",
      "JAPAN RESTAURANT WEEK 2010 -公式サイト\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# News selected\n",
    "\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.livedoor.com/article/detail/5985275/\n",
      "2011-11-01T12:27:00+0900\n",
      "ロンブー田村淳のTV業界論にネットユーザー激怒「嫌ならやめろ」\n",
      "先日、ロンドンブーツ1号2号の田村淳と、ジャーナリスト・津田大介による「テレビを巡るこれからのメディア論」の対談が「TV Bros.」10月29日発売号（東京ニュース通信社刊）に掲載された。\n",
      "\n",
      "その対談の中で、田村は\n",
      "「あまりに古い感覚でやっている人と仕事をするのはすごいストレスですよ。なんでこれが面白いってわからないんですか？って思うことがしょっちゅうある」\n",
      "「どうしても自分のやりたいことができなくなって、もうテレビは無理だと思ったらスパーンと全部やめる覚悟はありますよ」\n",
      "などと衝撃発言を行った。\n",
      "\n",
      "すると、この田村の発言を受けて、ネットの掲示板では田村バッシングが加熱、\n",
      "「なんでわかんないの？って感覚でみんな番組作ってるから視聴者が離れていってるんじゃないですかね」\n",
      "「お前がつまらないからだよ」\n",
      "「嫌ならやめろ」\n",
      "といった批判が殺到している。\n",
      "\n",
      "最近見る田村の発言は、ネットユーザーの怒りを買うものばかりだ。以前、ツイッター上でも\n",
      "「視聴者に、嫌ならテレビ見なければいいというのなら、あなた方ネット批判芸能人も、ネットをしなければよいのでは？」\n",
      "と問いかけられたことに対し、\n",
      "「ネチネチネチネチうるせーなぁ…って周りに言われない？」と発言、ネットユーザーを激怒させたこともあった。\n",
      "\n",
      "田村の尖った発言の数々は、ネットユーザーの怒りを増長させる傾向にあるだけに、今後の成り行きが心配される。\n",
      "\n",
      "【関連記事】\n",
      "・田村淳「刺激的な番組をつくれないとそれは衰退」。津田大介と“テレビを巡るメディア論”で対談\n",
      "\n",
      "【関連情報】\n",
      "・田村淳、TV業界を語る「古い感覚でやっている人と仕事をするのはすごいストレス。なんでこれが面白いってわからないの？」\n",
      "\n",
      "・ロンブー田村淳がツイッター民の正論に激怒「ネチネチうるせぇ」　こんな返し方しかできない芸人って\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# News whose cosine similarity has the highest correlation with a piece of news selected\n",
    "\n",
    "print(documents[index1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - It seems like those news are not correlated strongly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the definition\n",
    "\n",
    "cos_sim2, index2 = closest_cos_sim(tf_idf_array, tf_idf_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3311325289270498\n",
      "2872\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim2)\n",
    "print(index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.livedoor.com/article/detail/6655079/\n",
      "2012-06-13T19:25:00+0900\n",
      "小沢一郎氏の妻が支援者に離婚を報告。「週刊文春」報じる\n",
      "13日、Web版「週刊文春」は、民主党の元代表・小沢一郎氏の妻が、支援者宛に離婚したことを伝える手紙を送ったと報じ、ツイッターやネット掲示板で大きな話題になっている。\n",
      "\n",
      "記事によると、その手紙は「小沢は放射能が怖くて秘書と一緒に逃げだしました」「隠し子が発覚した際、小沢元代表は和子夫人に謝るどころか、『いつでも離婚してやる』と言い放ち、和子夫人は一時は自殺まで考えた」という小沢氏の支持者にとってはショッキングな内容となっている。\n",
      "\n",
      "ツイッターやネット掲示板では、「これが小沢一郎の本性か」「こりゃすごいな。てか、がっかりだなあ」などと、手紙の内容に驚く声が相次ぎ、その他にも「小沢潰しですかね?」「元秘書が交番で暴れて逮捕された件といい、小沢氏を潰したい何者かによる工作活動では?」といった声が挙がっていた。\n",
      "\n",
      "【関連情報】\n",
      "・小沢一郎夫人が支援者に「離婚しました」（週刊文春）\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# News selected\n",
    "\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.livedoor.com/article/detail/5633553/\n",
      "2011-06-14T16:29:00+0900\n",
      "クルマ色話 vol.1【ベンツCLS】 コレは斎藤佑樹クンが乗らないとダメでしょ!?\n",
      "20世紀的バリューを思いっきり引きずりつつ未来を目指すアラフォー自動車ジャーナリスト、小沢コージと業界の由美かおる!?　こと奇跡の超美人カーライフエッセイスト、吉田由美がお送りするお気楽かつキレキレな自動車トーク「クルマ色話」。一発目は昔の匂いを感じさせる、あの高級4ドアクーペ「メルセデス・ベンツCLS」だ！\n",
      "\n",
      "◆プロフィール\n",
      "小沢コージ\n",
      "バブル期にソアラ、プレリュードを横目で眺め、トレンディドラマを見、合コンしまくったスーパーカーブームど真ん中イケメン自動車ジャーナリスト。現在『BESTCAR』『ENGINE』『DIME』誌ほか『webCG』『日経TRENDY』『carview』などwebでも大活躍！\n",
      "\n",
      "吉田由美\n",
      "当時、ミスコン荒らしとして20コ以上のミスの肩書きを持ち、某専門誌「○×のすべて」に助手席モデルとして君臨。「経歴は編集長より長いかも（笑）」（本人談）という業界きっての謎の美女。今はカーライフエッセイストの名のもと「ブログの女王」として自動車メディアはもちろんファッション誌に無くてはならない存在となっている。\n",
      "\n",
      "\n",
      "\n",
      "最近、欲望ギラギラの男達が少なくなった……\n",
      "\n",
      "吉田：アタシ、このクルマ好きだなぁなんとなく。\n",
      "小沢コージ（以下、小沢）：なんとなくじゃなくってちゃんと理由言ってよ。ハタチの小娘じゃないんだからさ。\n",
      "吉田：いきなり感じ悪ぅ〜。彼女とケンカでもした？\n",
      "小沢：そんな相手、今いないよ。そんな余裕ナシ。で、その理由は。\n",
      "吉田：バブルの匂いがするじゃない。妙に落ち着く（笑）。\n",
      "小沢：理屈ないけど、それわかる。確かに欲望ギラギラだよね。CLSって6年前に出た元祖４ドアクーペで、一見クーペなのに実はセダンで「既婚だけど独身に見せたい」って願望まる出し（笑）。なおかつ旧 型はリアからはクラシックなジャガーEタイプそっくりで、新作はそれをマッチョかつ快適にした感じ。昔、日本にも「4ドアクーペ」のカリーナEDって あったけど、それよりずっとスケールデカいよ。中身はその時代のベンツＥクラスで味は保証付きだしさ。\n",
      "\n",
      "「カリーナED」初代モデルは1985年登場。徹底的に耽美性を追求し、クーペ並みの低い全高に強く傾斜した前後ピラー、富士山型の小さなグリーンハウス（キャビン）を持つ八頭身プロポーションを特徴とする。後席居住性には難があったが、その流麗なスタイリングは熟年層向けなイメージであったコロナセダン／カリーナセダンとは違い、何色にも染まっていない新進気鋭な存在として、若年層〜熟年層にかけて幅広い絶大な人気を博した。\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "吉田：その例え、なんだか古すぎて全然わからないけど、ともかく久々六本木が似合いそうとは思ったわ。実際、前のCLSはオジサンに人気あったし、女のコにも人気あった。乗ってる知り合いいっぱいいたもん。\n",
      " \n",
      "メルセデス・ベンツCLS 2005年モデル\n",
      "\n",
      "小沢：妙に愛人っぽく見えるよね。このクルマ。\n",
      "吉田：無駄な感じがするじゃない。BMWのX6とかもそうだけど、無駄にカッコ付けてて、アブラギッシュで勢いあって、いまどき「オレ、事業拡げるぜぇ！」みたいな（笑）。実際、初代CLSは女のコにモテ始めの「社長デビュー」が多かった気がする。\n",
      "小沢：やっぱそういうタイプ好きなの？　相変わらず。\n",
      "吉田：うっ、嫌いじゃないけど……だからダメなのかなぁアタシ。\n",
      "小沢：それがその美貌で未だ独身である一因ではあると思うけど……それが由美ちゃんっぽさだからいいんじゃないの？　別に。　\n",
      "吉田：なにそれ。\n",
      "\n",
      "\n",
      "\n",
      "コッチはコッチで韓流ブーム？\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "編集：ところでクルマはどうなんですか？　肝心の味の方は？\n",
      "吉田：えーと、普通にいいかな（笑）\n",
      "編集：は？\n",
      "小沢：いや分かる。特別不満を覚えないくらいにいいってことよね。ベースは現行Eクラスで、乗り心地から質感からガッチリ感まで全く不満はないし、前のは正直、スタイル優先過ぎてフロントに乗ると頭は前のガラスに付きそうだったし、リアにしろ足元や頭回りは狭すぎだったのが、今回から普通になった。特にリアはゆったり。\n",
      "吉田：そうそう！\n",
      "小沢：あとはエコだよ。メルセデスも今流行りのダウンサイジングコンセプトを採用して、V6エンジンは排気量3.5リッターのまま直噴化して部分リーンバーンになって燃費は約3割も良くなったし、日本のエコカー減税まで適用。V8はV8で本命のダウンサイジングエンジンは導入が遅れてるけど、その分、AMGモデルに新作5.5リッターV8が載って、これまた直噴ターボで燃費いい。厳密にはエンジンフィールは微妙にキレが落ちたけど、パワーは落ちるどころか伸びてるし、なにより燃費の良さには変えられない。\n",
      "吉田：とりあえず「ダウンサイジング」の意味を説明してもらえる？\n",
      "小沢：要は排気量抑える代わりに、直噴ターボ技術でパワー出して、効率よくなってんのよ。詳しく言うと……面倒なんで却下！\n",
      "吉田：とか言って実はわかってないんじゃないのぉ（笑）\n",
      "小沢：なにぃ（怒）　じゃ敢えて言うと直噴で燃料を燃焼室に直接入れてそこで冷却が出来てるから圧縮比が高められるのと、低回転からトルクが出るんで無駄に回さずに済んで多段ATと……\n",
      "吉田：わかったわかったわ……で、デザインはよりセクシーになった感じ？　前は華奢で繊細で、アタシも好きだったけど、今回は今回でちょっと太ったけど悪くない。より万人ウケのデザインになったような。\n",
      "小沢：言えてる。ところであれ、韓国人デザイナーが手掛けたって知ってた？　フーベルト・リーさんって30代の若手で在米コリアン3世。アメリカの有名プロダクトデザイン学校を首席クラスで卒業した人で、今、メルセデスのアドバンスドデザインのトップなんだって。\n",
      "吉田：ふぅーん。そっちも韓流ブームなのね。\n",
      "小沢：ちょっと違うけど、ま、そんな感じよ（苦笑）。\n",
      "\n",
      "\n",
      "川越シェフよ、もっと凄いクルマに乗ってくれ！\n",
      "\n",
      "小沢：でも確かに昔に比べてCLSに似合う日本人って減ったよね。昔は梅宮辰夫とか清原とかいっぱいいたのに。\n",
      "吉田：今だったら誰かな？　川越シェフとか？？\n",
      "小沢：いいねぇ！\n",
      "吉田でも本当は違うのよねぇ。実は私、彼と対談したことあるんだけど、普段クルマに乗ってないんだって。行き帰りはいつもタクシーで、お料理する時は、彼自身は絶対にご飯を食べないらしい。味覚が変わるからって。\n",
      "小沢：なるほど。ストイックで合理的なんだ。なんかいま風だけど、残念だなぁ。彼みたいな人が普通にCLSに乗ってると、世の中確実に盛り上がるのに。こう、上目遣いでアゴを上げながら、やっぱコレ、カッコ良すぎ！　とか言って欲しいのに。\n",
      "吉田：（笑）。\n",
      "小沢：実際、彼みたいなセンスのいい快楽主義者ってに海外なら絶対クルマにハマるんだよね。向こうの三つ星シェフにしろ、クルママニアは多くて有名なクラシックフェラーリのコレクターもいるらしい。\n",
      "吉田：向こうのセレブって普通にクルマ好きだもんね。ラルフ・ローレンさんもそうなんでしょ？\n",
      "小沢：よく知ってんじゃん。クラシック・ベントレーとかアルファロメオ8Cとか、ブガッティ・ベイロンとかに乗ってる。だからその辺は日本人はツライよね。規制が厳しすぎて、クルマに普通に寄りつかなくなってきてる。\n",
      "   \n",
      "\n",
      " \n",
      " \n",
      " \n",
      "クラシックベントレー アルファロメオ8C ブガッティ・ヴェイロン \n",
      "\n",
      "\n",
      "吉田：昔だったら巨人の松井とか、桑田とか絶対クルマ好きだったのに。成功した人はかならずいいクルマを持ってた。\n",
      "小沢：だから本当は祐ちゃんとかダルビッシュがCLSに乗ればいいんだよ。\n",
      "吉田：祐ちゃんって斎藤佑樹クン？　ダルビッシュのクルマは知らないけどそれは絶対ダメでしょ。\n",
      "小沢：なんで？\n",
      "吉田：だって今、彼乗ってるのスバルのフォレスターだもん。お父様が群馬のスバルの人だから。\n",
      "小沢：レ、レガシィB4!?　ダメだそりゃ……\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# News whose cosine similarity has the highest correlation with a piece of news selected\n",
    "\n",
    "print(documents[index2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Both of news are about a celebrity whose family name is \"小沢\". They are not a same person, though.\n",
    "    \n",
    "    - Those news are gossip articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 6] Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
