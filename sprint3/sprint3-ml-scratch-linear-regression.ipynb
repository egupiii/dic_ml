{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation from Scratch\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to implement algorithms by using the least kinds of libraries such as Numpy possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] Create a Class of Linear Regression from Scratch\n",
    "\n",
    "<br />\n",
    "\n",
    "I will create a class of linear regression and incorporate it to the pipeline of regressions on the \"sprint2\" directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Function\n",
    "\n",
    "<br />\n",
    "\n",
    "I implement the following hypothesis function of linear regression.\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\theta_0 x_0 + \\theta_1 x_1 + \\cdots + \\theta_j x_j + \\theta_n x_n \\ \\ \\ (x_0=1)\n",
    "$$\n",
    "\n",
    "$x$: feature vector\n",
    "\n",
    "$\\theta$: parameter vector\n",
    "\n",
    "$n$: the number of features\n",
    "\n",
    "$x_j$: jth feature vector\n",
    "\n",
    "$\\theta_j$: jth parameter(weight) vector\n",
    "\n",
    "I will implement the hypothesis function that can apply to any $n$, the number of features.\n",
    "\n",
    "<br />\n",
    "\n",
    "In addition, the following equation is the vector format.\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\theta^T x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "I will implement the following objective function of linear regression. This is the MSE, mean square error divided by 2 to use the steepest descent method easily.\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2\n",
    "$$\n",
    "\n",
    "$m$: the number of data input\n",
    "\n",
    "$h_\\theta()$: hypothesis function\n",
    "\n",
    "$x^{(i)}$: feature vector of ith sample\n",
    "\n",
    "$y^{(i)}$: correct values of ith sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steepest Descent Method\n",
    "\n",
    "<br />\n",
    "\n",
    "I will fit datasets by steepest descent method. The following equation is to update the jth parameter.\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m[(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}]\n",
    "$$\n",
    "\n",
    "$\\alpha$: learning rate\n",
    "\n",
    "$i$: index of a sample\n",
    "\n",
    "$j$: index of a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class of linear regression from scratch\n",
    "\n",
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    Implementation of linear regression from scratch\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter: int\n",
    "        The number of iteration\n",
    "    \n",
    "    lr: float\n",
    "        Learning rate\n",
    "    \n",
    "    no_bias: bool\n",
    "        True if not input the bias term\n",
    "    \n",
    "    verbose: bool\n",
    "        True if output the learning process\n",
    "    \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_: ndarray whose shape is (n_features,)\n",
    "        parameters\n",
    "    \n",
    "    self.loss: ndarray whose shape is (self.iter,)\n",
    "        records of loss on train dataset\n",
    "    \n",
    "    self.val_loss: ndarray whose shape is (self.iter,)\n",
    "        records of loss on validation dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # Record hyperparameters as attribute\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Prepare arrays for recording loss\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Fit linear regression. In a case of inputting validation dataset, return loss and accuracy of \n",
    "        the data per iteration.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray whose shape is (n_samples,n_features)\n",
    "            Features of train dataset\n",
    "        \n",
    "        y: ndarray whose shape is (n_samples,)\n",
    "            Correct values of train dataset\n",
    "        \n",
    "        X_val: ndarray whose shape is (n_samples,n_features)\n",
    "            Features of validation dataset\n",
    "        \n",
    "        y_val: ndarray whose shape is (n_samples,)\n",
    "            Correct values of validation dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        # Set a parameter randomly and transform it\n",
    "        self.coef_ = np.random.randn(X.shape[1])\n",
    "        self.coef_ = self.coef_.reshape(len(self.coef_),1)\n",
    "        ###print(\"fit-1\",self.coef_.shape)   # (2, 1)\n",
    "        \n",
    "        # Transform dataframes to let features rows\n",
    "        X = X.T\n",
    "        y = y.T\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            X_val = X.T\n",
    "            y_val = y_val.T\n",
    "        \n",
    "        if self.bias == True:\n",
    "            bias = np.array([1 for _ in range(X.shape[1])])\n",
    "            X = np.vstack((bias, X))\n",
    "            bias = np.array([1 for _ in range(y.shape[1])])\n",
    "            y = np.vstack((bias, y))\n",
    "        \n",
    "        # Update the theta and get loss of train dataset\n",
    "        for i in range(self.iter):\n",
    "            # Update the parameter\n",
    "            self.coef_ = self._gradient_descent(X, y)\n",
    "            print(\"fit-2\",self.coef_.shape)\n",
    "            # Compute the mean square mean\n",
    "            mse = self._compute_cost(X, y)\n",
    "            print(\"fit-3\",mse.shape)\n",
    "            # Record the errors\n",
    "            self.loss[i] = mse\n",
    "            # Return the loss if verbose is True\n",
    "            if self.verbose:\n",
    "                print(self.loss[i])\n",
    "            \n",
    "            # Get loss of validation datasets\n",
    "            if (X_val is not None) and (y_val is not None):\n",
    "                # Get the mean square error\n",
    "                val_mse = self._compute_cost(X_test, y_val)\n",
    "                # Record the errors\n",
    "                self.val_loss[i] = val_mse\n",
    "                # Return the loss if verbose is True\n",
    "                if self.verbose:\n",
    "                    print(self.val_loss[i])\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict by using linear regression\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray whose shape is (n_samples,n_features)\n",
    "            Samples\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        ndarray whose shape is (n_samples,1)\n",
    "            Results of the prediction by using linear regression\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bias == True:\n",
    "            bias = np.array([1 for _ in range(X.shape[1])])\n",
    "            X = np.vstack((bias, X))\n",
    "        \n",
    "        # Predict train dataset\n",
    "        y_pred = np.dot(self.coef_.T, X)   # (1, 4) * (4, 120)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    # Create a definition of hypothesis function of lunear regression\n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        Return hypothesis function of linear regression\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray whose shape is (n_samples,n_features)\n",
    "            Train dataset\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        ndarray whose shape is (n_samples,1)\n",
    "            Results of the prediction by hypothesis function of linear regression\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"_linear_hypothesis-1\",self.coef_.shape)\n",
    "        print(\"_linear_hypothesis-2\",X.shape)\n",
    "        \n",
    "        # Compute the hypothesis function\n",
    "        y_pred = np.dot(self.coef_.T, X)   # (1, 4) * (4, 120)\n",
    "        print(\"_linear_hypothesis-3\",y_pred.shape)\n",
    "         \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    # Create a definition to compute the mean square error\n",
    "    def _compute_cost(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute the mean square error. Import the \"MSE\" definition.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray whose shape is (n_samples,n_features)\n",
    "            train dataset\n",
    "\n",
    "        y: ndarray whose shape is (n_samples,1)\n",
    "            correct value\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        ndarray whose shape is (1,)\n",
    "            mean square error\n",
    "        \"\"\"\n",
    "\n",
    "        y_pred = self._linear_hypothesis(X)\n",
    "    \n",
    "        return self.MSE(y_pred, y)\n",
    "    \n",
    "    \n",
    "    # Create a definition of the mean square error\n",
    "    def MSE(self, y_pred, y):\n",
    "        \"\"\"\n",
    "        Return the mean square error\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred: ndarray whose shape is (n_samples,)\n",
    "            predited value\n",
    "        \n",
    "        y: ndarray whose shape is (n_samples,)\n",
    "            correct value\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        mse: numpy.float\n",
    "            mean square error\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"MSE-1\",y_pred.shape)\n",
    "        print(\"MSE-2\",y.shape)\n",
    "        \n",
    "        # Compute an error\n",
    "        error = y_pred - y\n",
    "        \n",
    "        # Sum errors\n",
    "        sum_errors = np.sum(error**2,axis=1) / error.shape[0]\n",
    "        \n",
    "        # Return the mean square error devided by 2\n",
    "        return sum_errors / (2*y.shape[1])\n",
    "    \n",
    "    \n",
    "    # Create a definition to fit datasets by steepest descent method\n",
    "    def _gradient_descent(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit datasets by steepest descent method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray whose shape is (n_samples,n_features)\n",
    "            train dataset\n",
    "        \n",
    "        y: ndarray whose shape is (n_samples,1)\n",
    "            correct value\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        ndarray whose shape is (1,)\n",
    "            parameter(weight)\n",
    "        \"\"\"\n",
    "        \n",
    "        print(X.reshape(2,1168))   # (2, 1)\n",
    "        \n",
    "        # Predict train dataset\n",
    "        y_pred = np.dot(self.coef_.T, X)   # (1, 4) * (2, 1)\n",
    "        print(\"_gradient_decsent-1\",y_pred.shape)\n",
    "        print(y.shape)\n",
    "        \n",
    "        # Compute the error and the mean square error\n",
    "        error = y_pred - y   # (1, 120)\n",
    "        print(\"_gradient_decsent-2\",error.shape)\n",
    "        \n",
    "        # Compute the gradient\n",
    "        grad = np.dot(X, error.T)   # (4, 120) * (120, 1)\n",
    "        print(\"_gradient_decsent-3\",grad.shape)\n",
    "        \n",
    "        print(\"_gradient_decsent-4\",y.shape)\n",
    "        print(\"_gradient_decsent-5\",self.coef_.shape)\n",
    "        \n",
    "        # Update the parameter\n",
    "        return self.coef_ - self.lr*grad/y.shape[1]\n",
    "    \n",
    "    \n",
    "    # Plot learning records\n",
    "    def plot_learning_record(self):\n",
    "        plt.plot(self.loss)\n",
    "        plt.plot(self.val_loss)\n",
    "        \n",
    "        plt.title(\"Learning Records\")\n",
    "        plt.xlabel(\"Number of Iterrations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the Class\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to validate the class by using the \"House Prices: Advanced Regression Techniques\" datasets on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare a dataset for the validation\n",
    "\n",
    "# Import the dataset\n",
    "train = pd.read_csv('\"House Prices- Advanced Regression Techniques\".train.csv')\n",
    "test = pd.read_csv('\"House Prices- Advanced Regression Techniques\".test.csv')\n",
    "\n",
    "# Split the datasets into explanatory and objective variables\n",
    "X = train.loc[:,[\"GrLivArea\", \"YearBuilt\"]].values\n",
    "X = X.reshape()\n",
    "\n",
    "y = train.SalePrice.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#Xy = pd.concat([X,y], axis=1)\n",
    "\n",
    "#df = Xy[Xy.Species!=0]\n",
    "\n",
    "# create and save a csv file of the dataframe\n",
    "#df.to_csv('iris_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kazukiegusa/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/kazukiegusa/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/sklearn/preprocessing/data.py:745: DeprecationWarning: The parameter y on transform() is deprecated since 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/Users/kazukiegusa/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.40709315, -0.45546896],\n",
       "       [ 0.08317013,  0.71860895],\n",
       "       [-1.39525026, -1.98829291],\n",
       "       ...,\n",
       "       [-1.26553079, -0.52069551],\n",
       "       [-0.19343756, -1.72738671],\n",
       "       [ 0.0526479 ,  1.17519481]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the dataset\n",
    "\n",
    "# Initialize the class\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the dataset\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transfer the datasets\n",
    "scaler.transform(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "\n",
    "slr = ScratchLinearRegression(num_iter=1000, lr=0.01, bias=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1314 1571  796 ...  864 1426 1555]\n",
      " [1957 1993 1910 ... 1955 1918 2007]]\n",
      "_gradient_decsent-1 (1, 1168)\n",
      "(1168,)\n",
      "_gradient_decsent-2 (1, 1168)\n",
      "_gradient_decsent-3 (2, 1)\n",
      "_gradient_decsent-4 (1168,)\n",
      "_gradient_decsent-5 (2, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-234d99e880c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mslr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-9419491609bd>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# Update the parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit-2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Compute the mean square mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-9419491609bd>\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# Update the parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "slr.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.T\n",
    "slr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] Plot Learning Curve\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to create a definition of drawing a plot of learning curves to validate the \"ScratchLinearRegression\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr.plot_learning_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
