{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation from Scratch\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to implement algorithms by using the least kinds of libraries such as Numpy possible.\n",
    "\n",
    "\n",
    "Decision tree can be used as both classification and regression. However, I will only implement classification one this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] Create a Definition to Compute Gini Impurity\n",
    "\n",
    "<br />\n",
    "\n",
    "I create a definition to compute Gini impurity that is an index value to split space.\n",
    "\n",
    "Gini impurity $I(t)$ against node $t$ can be computed by the following equation.\n",
    "\n",
    "$$\n",
    "I(t) = 1-\\sum_{i=1}^{K}P^2(C_i|t) = 1-\\sum_{i=1}^{K}(\\frac{N_{t,i}}{N_{t,all}})^{2}\n",
    "$$\n",
    "\n",
    "$t$: index of a node\n",
    "\n",
    "$i$: index of a class\n",
    "\n",
    "$K$: the number of classes\n",
    "\n",
    "$C_i$: ith class\n",
    "\n",
    "$P(C_i|t)$: ratio of $C_i$ in terms of $t$th node\n",
    "\n",
    "$N_{t,i}$: the number of samples coming into $i$th class in terms of $t$th node\n",
    "\n",
    "$N_{t,all}$: total number of samples in terms of $t$th node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] Create a Definition to Compute Information Gain\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to create a definition to compute information gains. When using the definition, I import the definition to compute Gini impurity. \n",
    "\n",
    "$$\n",
    "IG(p) = I(p)-\\frac{N_{left,all}}{N_{p,all}}I(left)-\\frac{N_{right,all}}{N_{p,all}}I(right)\n",
    "$$\n",
    "\n",
    "$p$: index of a parent node\n",
    "\n",
    "$left$: index of a node located on the left side of the decition tree\n",
    "\n",
    "$right$: index of a node located on the right side of the decition tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 3] Create a Class of Decision Tree Classifier whose depth is 1.\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to create a class of decision tree classifier whose depth is 1.\n",
    "\n",
    "<br />\n",
    "\n",
    "#### <u>Algorithms of Decision Tree</u>\n",
    "\n",
    "\n",
    "- I will focus on any feature, think of all the patterns of thresholds and compute each information gain. The method of letting each value a threshold is general. Indeed, the number of thresholds is one less than the number of samples. Then, I will choose the most biggest information gain among all kinds of the splits as the method of splitting the node.\n",
    "\n",
    "\n",
    "- A node whose gini impurity is 0, or a node whose depth is designated is named leaf. I am going to record what class the leaf is classified when the prediction. In a case that gini impurity is not 0, I will decide a class to classify the node by majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class of decision tree from scratch\n",
    "\n",
    "class ScratchDecisionTreeClassifier():\n",
    "    \"\"\"\n",
    "    Implementation of decision tree from scratch\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.threshold: float\n",
    "        thresholds\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Fit datasets by decision tree.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray whose shape is (n_samples,n_features)\n",
    "            Features of train dataset\n",
    "        \n",
    "        y: ndarray whose shape is (n_samples,)\n",
    "            Correct values of train dataset\n",
    "        \n",
    "        X_val: ndarray whose shape is (n_samples,n_features)\n",
    "            Features of validation dataset\n",
    "        \n",
    "        y_val: ndarray whose shape is (n_samples,)\n",
    "            Correct values of validation dataset\n",
    "        \"\"\"\n",
    "        \n",
    "#         # Change the vectors to a matrix\n",
    "#         y = y.reshape(len(y), 1)   # (,)\n",
    "#         if y_val is not None:\n",
    "#             y_val = y_val.reshape(len(y_val), 1)   # (,)\n",
    "        \n",
    "        # Transform arrays to move their features to rows\n",
    "        X = X.T\n",
    "#         y = y.T\n",
    "#         if (X_val is not None) and (y_val is not None):\n",
    "#             X_val = X_val.T\n",
    "#             y_val = y_val.T\n",
    "        \n",
    "        self.threshold = self._best_threshold(X, y)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Prediction\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray whose shape is (n_samples,n_features)\n",
    "            Samples\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        ndarray whose shape is (n_samples,1)\n",
    "            Results of the prediction\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transform arrays to move their features to rows\n",
    "        X = X.T\n",
    "#         print(\"predict-1, X=\",X.shape)   # (2,20)\n",
    "        \n",
    "#         print(\"predict-2, self.support_vector=\",self.support_vector.shape)   # (2,64)\n",
    "        \n",
    "        # Compute a linear kernel\n",
    "        linear_kernel = self._linear_kernel(X,self.support_vector)\n",
    "#         print(\"predict-3, linear_kernel=\",linear_kernel.shape)   # (20,64)\n",
    "        \n",
    "#         print(\"predict-4, label=\",self.label.shape)   # (1,64)\n",
    "#         print(\"predict-5, self.coef_=\",self.coef_.shape)   # (1,64)\n",
    "        \n",
    "        # Get the prediction\n",
    "        y_pred = np.dot(self.label*linear_kernel, self.coef_.T)\n",
    "        \n",
    "        # Classify the prediction\n",
    "        y_pred[y_pred>=0] = 1\n",
    "        y_pred[y_pred<0] = -1\n",
    "        \n",
    "        # Return the classified prediction\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    # Create a definition to compute a Gini impurity\n",
    "    def _gini_impurity(self, m, n):\n",
    "        \"\"\"\n",
    "        Compute Gini impurities.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        m: int\n",
    "            The number of samples\n",
    "        \n",
    "        n: int\n",
    "            The number of samples whose class is different with the class that the number of samples is m\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            Gini impurity\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute a Gini impurity\n",
    "        return 1-((m/m+n)**2 + (n/m+n)**2)\n",
    "    \n",
    "    \n",
    "    def _information_gain(self, m, n, s, t):\n",
    "        \"\"\"\n",
    "        Compute Gini impurities.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        m: int\n",
    "            The number of samples on left side\n",
    "        \n",
    "        n: int\n",
    "            The number of samples on left side whose class is different with the class that the number of samples is m\n",
    "        \n",
    "        s: int\n",
    "            The number of samples on right side\n",
    "        \n",
    "        t: int\n",
    "            The number of samples on right side whose class is different with the class that the number of samples is s\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "            Information gain\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute Gini impurities\n",
    "        left_gini_impurity = self._gini_impurity(m, n)\n",
    "        right_gini_impurity = self._gini_impurity(s, t)\n",
    "        \n",
    "        # Returns an information gain\n",
    "        return self._gini_impurity(m+n, s+t) - (m+n)/(m+n+s+t)*left_gini_impurity - (s+t)/(m+n+s+t)*right_gini_impurity\n",
    "    \n",
    "    \n",
    "    # Choose the best threshold\n",
    "    def _best_threshold(self, X, y):\n",
    "        # Set a temporary information gain\n",
    "        info_gain = 0\n",
    "        # Loop of features\n",
    "        for f in range(X.shape[0]):\n",
    "            # Delete duplicate values\n",
    "            non_duplicates_array = np.unique(X[f,:])\n",
    "            # Delete the minimum value of the arrays not containing duplicate values\n",
    "            non_dupli = np.delete(non_duplicates_array ,non_duplicates_array.min())\n",
    "            \n",
    "            # Loop of samples\n",
    "            for s in range(non_dupli.shape[1]):\n",
    "                # Update the threshold\n",
    "                temporary_threshold = non_dupli[:,s]\n",
    "                \n",
    "                # Change y to a list\n",
    "                y = y.tolist()\n",
    "                # Change values of y to only 2 kinds of values, 0 and 1\n",
    "                y = [1 if i == max(y) else 0 for i in y]\n",
    "                \n",
    "                # Get indices of the objective variable\n",
    "                index_true = np.where(y.index(1))\n",
    "                index_false = np.where(y.index(0))\n",
    "\n",
    "                # Count samples whose objective variable is TRUE/FALSE\n",
    "                n_more_true = np.sum(X[index_true,s] >= threshold)\n",
    "                n_more_false = np.sum(X[index_false,s] >= threshold)\n",
    "                n_less_true = np.sum(X[index_true,s] < threshold)\n",
    "                n_less_false = np.sum(X[index_false,s] < threshold)\n",
    "\n",
    "                # Update the information gain and the threshold\n",
    "                if self._information_gain(n_more_true, n_more_false, n_less_true, n_less_false) > info_gain:\n",
    "                    info_gain = self._information_gain(n_more_true, n_more_false, n_less_true, n_less_false)\n",
    "                    self.threshold = temporary_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
