{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation from Scratch\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to create a 3 layers of neural network for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset\n",
    "\n",
    "print(X_train.shape)   # (60000, 28, 28)\n",
    "print(X_test.shape)   # (10000, 28, 28)\n",
    "print(X_train[0].dtype)   # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten\n",
    "\n",
    "<br />\n",
    "\n",
    "I will transform the shape (1, 28, 28) of each image to (1, 784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "# Plot\n",
    "\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# Change it to float\n",
    "image = image.astype(np.float)\n",
    "# Create minus fractional value intentionally\n",
    "image -= 105.35\n",
    "\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "\n",
    "# Check the values\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Transform unit8 to float\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.max())   # 1.0\n",
    "print(X_train.min())   # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Transform correct labels that are 0 to 9 to \n",
    "\n",
    "# Initialize\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Fit\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "\n",
    "# Transform\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "print(y_train.shape)   # (60000,)\n",
    "print(y_train_one_hot.shape)   # (60000, 10)\n",
    "print(y_train_one_hot.dtype)   # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Split the train dataset\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)   # (48000, 784)\n",
    "print(X_val.shape)   # (12000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] Create a Class of Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to get a mini-batch\n",
    "\n",
    "class GetMiniBatch():\n",
    "    \"\"\"\n",
    "    Iterator to get a mini-batch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape (n_samples, n_features)\n",
    "      Train dataset\n",
    "    \n",
    "    y : ndarray, shape (n_samples, 1)\n",
    "      Correct values\n",
    "    \n",
    "    batch_size : int\n",
    "      Size of batch\n",
    "    \n",
    "    seed : int\n",
    "      Seed of random numbers of Numpy\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        \n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        \n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwardpropagation\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to create a forwardpropagation method of 3 layers of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class of a forwardpropagation method of 3 layers of neural network\n",
    "\n",
    "class Forwardpropagation():\n",
    "    \"\"\"\n",
    "    Forwardpropagation method\n",
    "    \"\"\"\n",
    "    \n",
    "    def weight_bias(self, n_features, n_nodes, sigma=0.01):\n",
    "        \"\"\"\n",
    "        Get a weight and a bias.\n",
    "        \"\"\"\n",
    "        \n",
    "        W = sigma * np.random.randn(n_features, n_nodes)\n",
    "        B = sigma * np.random.randn(n_nodes)[np.newaxis,:]\n",
    "        \n",
    "        return W, B\n",
    "    \n",
    "    \n",
    "    def layer_processing(self, X, W, B):\n",
    "        \"\"\"\n",
    "        Processing of a layer\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Feature vector\n",
    "\n",
    "        W : ndarray, shape (n_features, ith n_nodes)\n",
    "            Weight of ith layer\n",
    "\n",
    "        B : ndarray, shape (ith n_nodes,)\n",
    "            Bias of ith layer\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray, shape (n_samples, ith n_nodes)\n",
    "            Output\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.dot(X, W) + B\n",
    "    \n",
    "    \n",
    "    def activation_func(self, A, act_func):\n",
    "        \"\"\"\n",
    "        Activation function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray, shape (batch_size, ith n_nodes)\n",
    "            Output\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray, shape (batch_size, ith n_nodes)\n",
    "            Output\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sigmoid function\n",
    "        if act_func == \"sigmoid\":\n",
    "            return 1 / (1+np.exp(-A))\n",
    "        \n",
    "        # tanh\n",
    "        if act_func == \"tanh\":\n",
    "            return np.tanh(A)\n",
    "    \n",
    "    \n",
    "    def softmax_func(self, A3):\n",
    "        \"\"\"\n",
    "        Softmax function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        A : ndarray, shape (batch_size,)\n",
    "            Vector from previous layer of kth class\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray, shape (batch_size,)\n",
    "            Probability vector of kth class\n",
    "        \"\"\"\n",
    "        \n",
    "        A3 = A3 - np.max(A3)\n",
    "        \n",
    "        return np.exp(A3) / np.sum(np.exp(A3), axis=1)[:,np.newaxis]\n",
    "    \n",
    "    \n",
    "    # Objective function\n",
    "    def cross_entropy_loss(self, y, X3):\n",
    "        \"\"\"\n",
    "        Cross entropy loss\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : ndarray, shape (batch_size,)\n",
    "            Probability vector of kth class\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray, shape ()\n",
    "            Cross entropy loss\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.sum(-y * np.log(X3), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to create a backpropagation method of 3 layers of neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class of a backpropagation method of 3 layers of neural network\n",
    "\n",
    "class Backpropagation():\n",
    "    \"\"\"\n",
    "    Backpropagation method\n",
    "    \"\"\"\n",
    "    \n",
    "    def third_layer(self, y, X2, X3, W3):\n",
    "        # Gradient of loss for A3\n",
    "        delta1 = X3 - y\n",
    "        # Gradient of loss for B3\n",
    "        B3_grad = delta1\n",
    "        # Gradient of loss for W3\n",
    "        W3_grad = np.dot(X2.T, delta1)\n",
    "        # Gradient of loss for Z2\n",
    "        Z2_grad = np.dot(delta1, W3.T)\n",
    "        \n",
    "        return delta1, B3_grad, W3_grad, Z2_grad\n",
    "    \n",
    "    \n",
    "    def second_layer(self, X1, A2, W2, W3, delta1, Z2_grad):\n",
    "        # Gradient of loss for A2\n",
    "        delta2 = (1-np.tanh(A2)**2) * Z2_grad        \n",
    "        # Gradient of loss for B2\n",
    "        B2_grad = delta2\n",
    "        # Gradient of loss for W2\n",
    "        W2_grad = np.dot(X1.T, delta2)\n",
    "        # Gradient of loss for Z1\n",
    "        Z1_grad = np.dot(delta2, W2.T)\n",
    "        \n",
    "        return delta2, B2_grad, W2_grad, Z1_grad\n",
    "    \n",
    "    \n",
    "    def first_layer(self, X, A1, W2, delta2, Z1_grad):\n",
    "        # Gradient of loss for A1\n",
    "        delta3 = (1-np.tanh(A1)**2) * Z1_grad\n",
    "        # Gradient of loss for B1\n",
    "        B1_grad = delta3\n",
    "        # Gradient of loss for W1\n",
    "        W1_grad = np.dot(X.T, delta3)\n",
    "        \n",
    "        return delta3, B1_grad, W1_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class of neural network classifier\n",
    "\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    Implement simple 3 layers of neural network classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_epoch : int\n",
    "        Number of epochs\n",
    "    \n",
    "    act_func : str\n",
    "        Name of activation function\n",
    "        \n",
    "    lr : float\n",
    "        Learning rate\n",
    "    \n",
    "    n_features : int\n",
    "        Number of features\n",
    "    \n",
    "    n_nodes1 : int\n",
    "        Number of nodes of 1st layer\n",
    "    \n",
    "    n_nodes2 : int\n",
    "        Number of nodes of 2nd layer\n",
    "    \n",
    "    n_output : int\n",
    "        Number of classes of output (Number of nodes of 3rd layer)\n",
    "    \n",
    "    sigma : float\n",
    "        Standard deviation of Gaussian distribution\n",
    "    \n",
    "    verbose : bool\n",
    "        True if outputting learning process\n",
    "    \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    loss : ndarray, shape (self.epoch,)\n",
    "        Records of loss on train dataset\n",
    "    \n",
    "    val_loss : ndarray, shape (self.epoch,)\n",
    "        Records of loss on validation dataset\n",
    "    \n",
    "    W1 : ndarray, shape (n_features, n_nodes1)\n",
    "        Weight of 1st layer\n",
    "    \n",
    "    B1 : ndarray, shape (n_nodes1,)\n",
    "        Bias of 1st layer\n",
    "    \n",
    "    W2 : ndarray, shape (n_nodes1, n_nodes2)\n",
    "        Weight of 2st layer\n",
    "    \n",
    "    B2 : ndarray, shape (n_nodes2,)\n",
    "        Bias of 2st layer\n",
    "    \n",
    "    W3 : ndarray, shape (n_nodes2, n_nodes3)\n",
    "        Weight of 3st layer\n",
    "    \n",
    "    B3 : ndarray, shape (n_nodes3,)\n",
    "        Bias of 3st layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_epoch, batch_size, act_func, lr, n_features, n_nodes1, n_nodes2, n_output, sigma, verbose=True):\n",
    "        # Record hyperparameters as attribute\n",
    "        self.epoch = num_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.act_func = act_func\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Prepare arrays for recording loss\n",
    "        self.loss = np.zeros(self.epoch)\n",
    "        self.val_loss = np.zeros(self.epoch)\n",
    "        \n",
    "        # Initialize\n",
    "        fp = Forwardpropagation()\n",
    "        bp = Backpropagation()\n",
    "        \n",
    "        # Get an initial values\n",
    "        self.W1, self.B1 = fp.weight_bias(n_features, n_nodes1, sigma)\n",
    "        self.W2, self.B2 = fp.weight_bias(n_nodes1, n_nodes2, sigma)\n",
    "        self.W3, self.B3 = fp.weight_bias(n_nodes2, n_output, sigma)\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Fit neural network classifier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Features of train dataset\n",
    "        \n",
    "        y : ndarray, shape (n_samples, )\n",
    "            Correct values of train dataset\n",
    "        \n",
    "        X_val : ndarray, shape (n_samples, n_features)\n",
    "            Features of validation dataset\n",
    "        \n",
    "        y_val : ndarray, shape (n_samples, )\n",
    "            Correct values of validation dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize\n",
    "        get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "        if (X_val is not None) and (y_val is not None):\n",
    "            get_mini_batch_val = GetMiniBatch(X_val, y_val, batch_size=self.batch_size)\n",
    "        \n",
    "        # Initialize\n",
    "        fp = Forwardpropagation()\n",
    "        bp = Backpropagation()\n",
    "        \n",
    "        # Fit\n",
    "        if self.verbose:\n",
    "            count = 0\n",
    "        for i in range(self.epoch):\n",
    "            if (X_val is not None) and (y_val is not None):\n",
    "                for ((mini_X_train, mini_y_train), (mini_X_val_train, mini_y_val_train)) in zip(get_mini_batch, get_mini_batch_val):\n",
    "                    # Forwardpropagation\n",
    "                    # 1st layer\n",
    "                    # Processing of the layer\n",
    "                    A1 = fp.layer_processing(mini_X_train, self.W1, self.B1)\n",
    "                    # Activation function\n",
    "                    X1 = fp.activation_func(A1, self.act_func)\n",
    "\n",
    "                    # 2nd layer\n",
    "                    # Processing of the layer\n",
    "                    A2 = fp.layer_processing(X1, self.W2, self.B2)\n",
    "                    # Activation function\n",
    "                    X2 = fp.activation_func(A2, self.act_func)\n",
    "\n",
    "                    # 3rd layer (Softmax)\n",
    "                    # Processing of the layer\n",
    "                    A3 = fp.layer_processing(X2, self.W3, self.B3)\n",
    "                    # Activation function\n",
    "                    X3 = fp.softmax_func(A3)\n",
    "\n",
    "                    # 4th layer (Cross entropy loss)\n",
    "                    if self.verbose:\n",
    "                        L = fp.cross_entropy_loss(mini_y_train, X3)\n",
    "\n",
    "\n",
    "                    # Backpropagation\n",
    "                    # 3rd layer\n",
    "                    delta1, B3_grad, W3_grad, Z2_grad = bp.third_layer(mini_y_train, X2, X3, self.W3)\n",
    "                    # Update weight and bias\n",
    "                    self.B3 = self.B3 - self.lr*np.average(B3_grad, axis=0)\n",
    "                    self.W3 = self.W3 - self.lr*W3_grad/W3_grad.shape[1]\n",
    "\n",
    "                    # 2nd layer\n",
    "                    delta2, B2_grad, W2_grad, Z1_grad = bp.second_layer(X1, A2, self.W2, self.W3, delta1, Z2_grad)\n",
    "                    # Update weight and bias\n",
    "                    self.B2 = self.B2 - self.lr*np.average(B2_grad, axis=0)\n",
    "                    self.W2 = self.W2 - self.lr*W2_grad/W2_grad.shape[1]\n",
    "\n",
    "                    # 1st layer\n",
    "                    delta3, B1_grad, W1_grad = bp.first_layer(mini_X_train, A1, self.W2, delta2, Z1_grad)\n",
    "                    # Update weight and bias\n",
    "                    self.B1 = self.B1 - self.lr*np.average(B1_grad, axis=0)\n",
    "                    self.W1 = self.W1 - self.lr*W1_grad/W1_grad.shape[1]\n",
    "                    \n",
    "                    \n",
    "                    # Validation data\n",
    "                    # Forwardpropagation\n",
    "                    # 1st layer\n",
    "                    # Processing of the layer\n",
    "                    A1 = fp.layer_processing(mini_X_val_train, self.W1, self.B1)\n",
    "                    # Activation function\n",
    "                    X1 = fp.activation_func(A1, self.act_func)\n",
    "\n",
    "                    # 2nd layer\n",
    "                    # Processing of the layer\n",
    "                    A2 = fp.layer_processing(X1, self.W2, self.B2)\n",
    "                    # Activation function\n",
    "                    X2 = fp.activation_func(A2, self.act_func)\n",
    "\n",
    "                    # 3rd layer (Softmax)\n",
    "                    # Processing of the layer\n",
    "                    A3 = fp.layer_processing(X2, self.W3, self.B3)\n",
    "                    # Activation function\n",
    "                    X3 = fp.softmax_func(A3)\n",
    "\n",
    "                    # 4th layer (Cross entropy loss)\n",
    "                    if self.verbose:\n",
    "                        L_val = fp.cross_entropy_loss(mini_y_val_train, X3)\n",
    "            \n",
    "            \n",
    "            else:\n",
    "                for ((mini_X_train, mini_y_train), (mini_X_val_train, mini_y_val_train)) in zip(get_mini_batch, get_mini_batch_val):\n",
    "                    # Forwardpropagation\n",
    "                    # 1st layer\n",
    "                    # Processing of the layer\n",
    "                    A1 = fp.layer_processing(mini_X_train, self.W1, self.B1)\n",
    "                    # Activation function\n",
    "                    X1 = fp.activation_func(A1, self.act_func)\n",
    "\n",
    "                    # 2nd layer\n",
    "                    # Processing of the layer\n",
    "                    A2 = fp.layer_processing(X1, self.W2, self.B2)\n",
    "                    # Activation function\n",
    "                    X2 = fp.activation_func(A2, self.act_func)\n",
    "\n",
    "                    # 3rd layer (Softmax)\n",
    "                    # Processing of the layer\n",
    "                    A3 = fp.layer_processing(X2, self.W3, self.B3)\n",
    "                    # Activation function\n",
    "                    X3 = fp.softmax_func(A3)\n",
    "\n",
    "                    # 4th layer (Cross entropy loss)\n",
    "                    if self.verbose:\n",
    "                        L = fp.cross_entropy_loss(mini_y_train, X3)\n",
    "\n",
    "\n",
    "                    # Backpropagation\n",
    "                    # 3rd layer\n",
    "                    delta1, B3_grad, W3_grad, Z2_grad = bp.third_layer(mini_y_train, X2, X3, self.W3)\n",
    "                    # Update weight and bias\n",
    "                    self.B3 = self.B3 - self.lr*np.average(B3_grad, axis=0)\n",
    "                    self.W3 = self.W3 - self.lr*W3_grad/W3_grad.shape[1]\n",
    "\n",
    "                    # 2nd layer\n",
    "                    delta2, B2_grad, W2_grad, Z1_grad = bp.second_layer(X1, A2, self.W2, self.W3, delta1, Z2_grad)\n",
    "                    # Update weight and bias\n",
    "                    self.B2 = self.B2 - self.lr*np.average(B2_grad, axis=0)\n",
    "                    self.W2 = self.W2 - self.lr*W2_grad/W2_grad.shape[1]\n",
    "\n",
    "                    # 1st layer\n",
    "                    delta3, B1_grad, W1_grad = bp.first_layer(mini_X_train, A1, self.W2, delta2, Z1_grad)\n",
    "                    # Update weight and bias\n",
    "                    self.B1 = self.B1 - self.lr*np.average(B1_grad, axis=0)\n",
    "                    self.W1 = self.W1 - self.lr*W1_grad/W1_grad.shape[1]\n",
    "            \n",
    "            \n",
    "            # Output learning process if verbose is True\n",
    "            if self.verbose:\n",
    "                self.loss[count] = sum(L) / self.batch_size\n",
    "                if (X_val is not None) and (y_val is not None):\n",
    "                    self.val_loss[count] = sum(L_val) / self.batch_size\n",
    "                    print(\"{0}th loss: {1}, val_loss: {2}\".format(count+1, self.loss[count], self.val_loss[count]))\n",
    "                else:\n",
    "                    print(self.loss[count])\n",
    "                count += 1\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict by neural network classifier.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            Samples\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray, shape (n_samples, 1)\n",
    "            Results of prediction\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize\n",
    "        fp = Forwardpropagation()\n",
    "        \n",
    "        # Forwardpropagation\n",
    "        # 1st layer\n",
    "        # Processing of the layer\n",
    "        A1 = fp.layer_processing(X, self.W1, self.B1)\n",
    "        # Activation function\n",
    "        X1 = fp.activation_func(A1, self.act_func)\n",
    "\n",
    "        # 2nd layer\n",
    "        # Processing of the layer\n",
    "        A2 = fp.layer_processing(X1, self.W2, self.B2)\n",
    "        # Activation function\n",
    "        X2 = fp.activation_func(A2, self.act_func)\n",
    "\n",
    "        # 3rd layer (Softmax)\n",
    "        # Processing of the layer\n",
    "        A3 = fp.layer_processing(X2, self.W3, self.B3)\n",
    "        # Activation function\n",
    "        X3 = fp.softmax_func(A3)\n",
    "        \n",
    "        return np.argmax(X3, axis=1)\n",
    "    \n",
    "    \n",
    "    # Plot learning records\n",
    "    def plot_learning_record(self):\n",
    "        \"\"\"\n",
    "        Plot learning records.\n",
    "        \"\"\"\n",
    "        \n",
    "        plt.figure(facecolor=\"azure\", edgecolor=\"coral\")\n",
    "        \n",
    "        plt.plot(self.loss, label=\"loss\")\n",
    "        plt.plot(self.val_loss, label=\"val_loss\")\n",
    "        \n",
    "        plt.title(\"Learning Records\")\n",
    "        plt.xlabel(\"Number of Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # Compute index values\n",
    "    def compute_index_values(self, y, y_pred):\n",
    "        \"\"\"\n",
    "        Compute Index values.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray, shape(n_samples,n_features)\n",
    "            Features of train dataset\n",
    "        \n",
    "        y: ndarray, shape(n_samples,)\n",
    "            Correct values of train dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        # Return index values\n",
    "        print(\"accuracy score:\", accuracy_score(y, y_pred))\n",
    "#         print(\"precision score:\", precision_score(y, y_pred))\n",
    "#         print(\"recall score:\", recall_score(y, y_pred))\n",
    "#         print(\"f1 score:\", precision_score(y, y_pred))\n",
    "#         print(\"confusion matrix:\")\n",
    "#         print(confusion_matrix(y, y_pred))\n",
    "    \n",
    "    \n",
    "    def plot_misclassification(self, X_val, y_val, y_pred):\n",
    "        \"\"\"\n",
    "        Plot results of misclassification. Show \"Results of prediction/Corrects\" above images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : ndarray, shape (n_samples,)\n",
    "            Results of prediction\n",
    "        \n",
    "        y_val : ndarray, shape (n_samples,)\n",
    "            Correct labels of validation data\n",
    "        \n",
    "        X_val : ndarray, shape (n_samples, n_features)\n",
    "            Features of validation data\n",
    "        \"\"\"\n",
    "        \n",
    "        # Number of results I want to plot\n",
    "        num = 36\n",
    "\n",
    "        true_false = y_pred==y_val\n",
    "        false_list = np.where(true_false==False)[0].astype(np.int)\n",
    "\n",
    "        if false_list.shape[0] < num:\n",
    "            num = false_list.shape[0]\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
    "        for i in range(num):\n",
    "            ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
    "            ax.set_title(\"{} / {}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n",
    "            ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "nn = ScratchSimpleNeuralNetrowkClassifier(100, 10, \"tanh\", 0.001, 784, 400, 200, 10, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th loss: 2.3010066529852806, val_loss: 2.3034542086745846\n",
      "2th loss: 2.2981212243531184, val_loss: 2.302916263400795\n",
      "3th loss: 2.2954495645754043, val_loss: 2.302349370700091\n",
      "4th loss: 2.2929537321008953, val_loss: 2.301746977758723\n",
      "5th loss: 2.2906006781086776, val_loss: 2.3011041425129584\n",
      "6th loss: 2.288361360617279, val_loss: 2.3004169999465827\n",
      "7th loss: 2.286210010226197, val_loss: 2.299682361308431\n",
      "8th loss: 2.28412351626791, val_loss: 2.298897412828901\n",
      "9th loss: 2.282080908928316, val_loss: 2.2980594885288994\n",
      "10th loss: 2.2800629179194187, val_loss: 2.2971658977628957\n",
      "11th loss: 2.27805159208175, val_loss: 2.2962137927235498\n",
      "12th loss: 2.2760299671951154, val_loss: 2.295200064616925\n",
      "13th loss: 2.273981771512521, val_loss: 2.2941212598572793\n",
      "14th loss: 2.2718911602618577, val_loss: 2.292973509625533\n",
      "15th loss: 2.2697424716957895, val_loss: 2.2917524676352405\n",
      "16th loss: 2.267519998295079, val_loss: 2.2904532520686867\n",
      "17th loss: 2.2652077675059785, val_loss: 2.289070388471604\n",
      "18th loss: 2.262789326965784, val_loss: 2.287597750996191\n",
      "19th loss: 2.260247529578953, val_loss: 2.2860284998113607\n",
      "20th loss: 2.25756431407937, val_loss: 2.284355012798286\n",
      "21th loss: 2.2547204768776608, val_loss: 2.2825688098517096\n",
      "22th loss: 2.25169543106918, val_loss: 2.280660468241399\n",
      "23th loss: 2.2484669484919366, val_loss: 2.278619527578692\n",
      "24th loss: 2.245010880700756, val_loss: 2.2764343830050087\n",
      "25th loss: 2.24130085469743, val_loss: 2.2740921652994555\n",
      "26th loss: 2.237307939269981, val_loss: 2.271578606722898\n",
      "27th loss: 2.2330002779078795, val_loss: 2.2688778916169285\n",
      "28th loss: 2.228342684558578, val_loss: 2.2659724911114516\n",
      "29th loss: 2.2232961990937112, val_loss: 2.2628429818368927\n",
      "30th loss: 2.2178176004295733, val_loss: 2.2594678493850435\n",
      "31th loss: 2.2118588770328476, val_loss: 2.255823278550477\n",
      "32th loss: 2.2053666573685144, val_loss: 2.25188293429325\n",
      "33th loss: 2.1982816071652236, val_loss: 2.247617740133591\n",
      "34th loss: 2.1905378067972303, val_loss: 2.242995664633811\n",
      "35th loss: 2.18206213142482, val_loss: 2.2379815321385244\n",
      "36th loss: 2.172773669847373, val_loss: 2.2325368815133055\n",
      "37th loss: 2.1625832366093354, val_loss: 2.2266199067909502\n",
      "38th loss: 2.151393057283756, val_loss: 2.220185526952225\n",
      "39th loss: 2.139096740643532, val_loss: 2.2131856489409483\n",
      "40th loss: 2.125579694951573, val_loss: 2.205569708424033\n",
      "41th loss: 2.1107201992179663, val_loss: 2.1972855958096797\n",
      "42th loss: 2.0943914020857, val_loss: 2.188281097925453\n",
      "43th loss: 2.076464584723188, val_loss: 2.178506002813737\n",
      "44th loss: 2.0568140758378908, val_loss: 2.167915015928525\n",
      "45th loss: 2.0353242210608724, val_loss: 2.1564716037771006\n",
      "46th loss: 2.0118987440757814, val_loss: 2.1441527916066194\n",
      "47th loss: 1.9864726347514705, val_loss: 2.130954765901529\n",
      "48th loss: 1.9590262931382916, val_loss: 2.116898845112609\n",
      "49th loss: 1.9296009977099513, val_loss: 2.1020369826333765\n",
      "50th loss: 1.8983138713887118, val_loss: 2.086455511978275\n",
      "51th loss: 1.8653695523076461, val_loss: 2.070275487036887\n",
      "52th loss: 1.8310650998904747, val_loss: 2.0536479636562914\n",
      "53th loss: 1.7957847995387937, val_loss: 2.036743196164955\n",
      "54th loss: 1.7599829195354861, val_loss: 2.0197341150619317\n",
      "55th loss: 1.724155114394931, val_loss: 2.0027763600144453\n",
      "56th loss: 1.688802305760639, val_loss: 1.9859888538972181\n",
      "57th loss: 1.6543931838041526, val_loss: 1.969439513657098\n",
      "58th loss: 1.6213318152129634, val_loss: 1.9531396634910698\n",
      "59th loss: 1.5899350653815443, val_loss: 1.9370483205345264\n",
      "60th loss: 1.5604216218533504, val_loss: 1.9210847682575776\n",
      "61th loss: 1.5329117437997966, val_loss: 1.9051458574764173\n",
      "62th loss: 1.5074353515299612, val_loss: 1.8891239140553968\n",
      "63th loss: 1.4839457257160666, val_loss: 1.8729218858772316\n",
      "64th loss: 1.4623363758146057, val_loss: 1.8564638284728683\n",
      "65th loss: 1.442459045616245, val_loss: 1.839700329139412\n",
      "66th loss: 1.4241411574862948, val_loss: 1.8226095563121685\n",
      "67th loss: 1.4072013215857853, val_loss: 1.8051951614957282\n",
      "68th loss: 1.3914619554365568, val_loss: 1.7874823454879007\n",
      "69th loss: 1.3767585668944573, val_loss: 1.7695132016583603\n",
      "70th loss: 1.3629457429155551, val_loss: 1.751342123558682\n",
      "71th loss: 1.349900242618372, val_loss: 1.7330317213402922\n",
      "72th loss: 1.3375217693116248, val_loss: 1.7146494003058552\n",
      "73th loss: 1.3257320225204867, val_loss: 1.6962645556735616\n",
      "74th loss: 1.314472574136634, val_loss: 1.6779462438048545\n",
      "75th loss: 1.3037020303327276, val_loss: 1.6597611879758376\n",
      "76th loss: 1.2933928610573158, val_loss: 1.6417720318752913\n",
      "77th loss: 1.2835282054657637, val_loss: 1.6240358254731215\n",
      "78th loss: 1.2740988890377376, val_loss: 1.6066027827488287\n",
      "79th loss: 1.265100813423948, val_loss: 1.589515372246716\n",
      "80th loss: 1.2565328063394618, val_loss: 1.5728077893941126\n",
      "81th loss: 1.2483949529053167, val_loss: 1.5565058252666484\n",
      "82th loss: 1.2406873784414898, val_loss: 1.5406271054878693\n",
      "83th loss: 1.2334094196436685, val_loss: 1.5251816385677077\n",
      "84th loss: 1.2265591062953045, val_loss: 1.5101725928166516\n",
      "85th loss: 1.2201328758603478, val_loss: 1.4955972163045232\n",
      "86th loss: 1.2141254533338304, val_loss: 1.4814478218780867\n",
      "87th loss: 1.208529843275635, val_loss: 1.4677127737975006\n",
      "88th loss: 1.2033373957603588, val_loss: 1.4543774292181637\n",
      "89th loss: 1.1985379204305961, val_loss: 1.4414250032007874\n",
      "90th loss: 1.194119831921035, val_loss: 1.428837338587731\n",
      "91th loss: 1.1900703157556725, val_loss: 1.4165955716562837\n",
      "92th loss: 1.1863755071440714, val_loss: 1.4046806913703969\n",
      "93th loss: 1.1830206768021956, val_loss: 1.3930739949308084\n",
      "94th loss: 1.1799904187633596, val_loss: 1.3817574457273063\n",
      "95th loss: 1.1772688356563181, val_loss: 1.3707139421177081\n",
      "96th loss: 1.1748397174089307, val_loss: 1.3599275069373018\n",
      "97th loss: 1.1726867099081384, val_loss: 1.3493834084279435\n",
      "98th loss: 1.1707934708212466, val_loss: 1.339068223474746\n",
      "99th loss: 1.1691438105170981, val_loss: 1.3289698537506092\n",
      "100th loss: 1.167721816761059, val_loss: 1.3190775047000538\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "\n",
    "nn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 9, 8, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] Plot Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "\n",
    "nn.plot_learning_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 3] Compute Evaluation Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.766\n"
     ]
    }
   ],
   "source": [
    "nn.compute_index_values(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Option] Check Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kazukiegusa/.pyenv/versions/anaconda3-5.3.0/lib/python3.6/site-packages/ipykernel_launcher.py:349: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAABBCAYAAABvsB5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAACE1JREFUeJztnW9MVecdxz8/hmUG26DYLXQNl1QnglHahPTFJpcXNS1uMRGLNZOk1WicWeYMvOBFSRb/MuqWvRkvOhcrtotjibhO3YgvNv+ArsnERBJ3C4ZukNQpjk0UaGa4PHtxzmUHuH/O4d7LLZ7fJ3kSznme73mee57vfc7v+XlAMcagKH4jK9MDUJRMoMZXfIkaX/ElanzFl6jxFV+ixld8iRpf8SXzanwRaRWRJyLyj/nsV/EHIrJKREZFJCwiu+O1TWh8+0LOEhaRXyTQHBeRPTGqjxljihxt3xKR6yIyLiKXE40nSl91InJPREZE5AMRyfGg3S4iAyIyJiIfi8gyD9rXRORTe9yXRCTgQfuyiHTb2m4RedmDtsjub9zuf4MH7TIR+Z39eQdEZLsHbY59fx/Z97veg1ZE5D0RGbbLMRERD3pXc2yM6TPGLAE6E17UGOO6ALnAKBBM0G4QeDHK+VbgyIxzG4C3gB8Dlz2O5w3gPrAGWApcBppdatcAj4EgsAQ4DbS51C4HRoCtwFeBnwKfuNQ+AwwAdUAO8CP7+BmX+r8APwcWA28CD4HnXWp/A/zW/rzr7c+wxqX2J7ahlgIlwD2gyqX2+0Av8CLwDeBvwN50zbHdZnfcNh6N9g7wGSBx2qwDemLUzTK+o273HIx/GmhyHL8G3HOpbQJOO45XAE+AZ11o9wDXHce5wBfAahfa14HPnffQXigSmghYBfzXOUbbjAlNZI/xCbDKce4jDwvF58DrjuPDHhaK68Aex/EuDwuF5zl2Y3yvMf47wIfGvnoMvgP8weN158oa4Jbj+BbwdRHJ96o1xvRjG2MO2jGg3z7vRtsz4x72eNB+Zox57Dh3y6V2FRA2xvR51YrIUuAFZt9rN/1C9HlKRut2jmPi2vgiUghUAqcSNP0u8MdkBuWBJViP6wiRn5+dgzaiV210baS9V220vkeAJS7j/GTmOCZeVvy3gS5jzN9jNRCRPGA11qNtPhgFnnMcR35+HKVtIm1Er9ro2kh7r9pofT8HjCaIHOJp8dB3VLwaP9Fq/wbwJ2NMeO5D8sRtoMxxXAbcN8YMe9WKyEtYm82+mIrY2lysPcJtl9p1M1a7dR60L4mIc7Urc6ntA7JF5JtetcaY/wD/ZPa9dtMvRJ+nZLRu5zg2LjcY3wLGSLDxAz4E3o5T38rsrM5XsDIje4Gr9s+LXI6rCiu7UIq14/8z3rI6j4AKrI3fr3G/WXse65H7pj3e9/Ce1dmP9UX7Id6yOp8AP7P7rcZbVqcNK7OTC3wbb1mdZuCKfZ9XY30R3GZ19gIhrIzOC1hmdpvV8TzHpCqrA/wS+ChBG7Fvxtc8Gn8HYGaUVkf9KFAR55r1WOmuR8BJIMdRdxuojaPdjpVRGQN+Dyxz1HUA78bRbgA+xcrmXAaKHHXvA+/H0b4CdNvam8Arjrp3gY442iK7vy+wUoQbHHW1wO042mXAx/bnHQS2O+oqsMKPWNoc4AP7Pt8H6h11hfY8FcbxxjHg33Y5xvSsVkrn2I3xxW6YNCLyKtBijHk1TptfAd/DelStSEnHimJjh3F/xXqq/sAY0xqzbYqNn2+M6UjJBRUljaTM+IqykNC3MxVfosZXfEl2pgew0BGRjMaKxhjXbzkq/0dXfMWXqPG/pOzatYtwOIwxhhUrNPObatT4ii/RGP9LQmlpKeXl5QA0NjZSUFCAMYbJyUlKS0vp7+/P8AifLjSPnySp2NyWlZVx9uxZxsfHASgpKXFenytXrrBp0ybGxsZmaXVzOzd0xc8gIkJJSQm1tbUEAgEiL2zOXIyCwSDr16/n4sWLmRjmU4nG+Blky5YtjI+Ps3Hjxmnni4uLyc7OZtu2bVPngsHgfA/vqUaNP49UVlZOFYDy8nI6OzunhTZO2tvbOXz4MGB9SZTUoTF+kriN8fPy8rh58yYA+fn5dHV1UVVVhTGGu3fvcurUKa5duwbA1atXp+L9QCBAV1cXo6OjUb8gGuPPETfv42uJXZj9uwSzSk1Njbl06ZKZmJiYVsLhsDlw4IAJBAJx9b29vSYUCkWty/TnX6hFQx3Fl2iokySJQp2VK1fS29sbta6lpYX9+/cn7KOvr4/8/Hyqq6sBKxSKYDTUmROazkwjlZWVnDx5MhIS8eDBAwBu3LgBMLVxjUdRURGLFy9maGhomuGV5FDjp4m8vDwaGhooLCwE4MSJExw/fhyA7u5u19fZuXMnBQUF3LlzJy3j9C2Z3mQs9EKMDem+ffumNrFtbW0JN8DRSk1NjQmHw2ZiYkI3t6met0wPYKGXWKY1xphwOGyGh4dNMBj0ZPiioiJz8OBBEw6Hp67T29urxk9h0VAnTUxOTjI0NMSOHTsSxua5ubnT/mW2qamJtWvXYoz1kpoxhkOHDqV7yL5CjZ9GQqEQXV1dMevz8vIIBoPU1dVRUVER812djo4OfU8nxWgeX/ElmsdPklh5/MhvT50/f56BgQEAjhw5AsDWrVspLi6mrKyMiooK57WA6St+Z2cnmzdvZmRk5h86JtJW8/hzQI2fJLGMH4nP45GVlTWtTVaW9QCenJzk4cOHVFdXJ9wfqPHnhsb4aSKyKfXS5sKFC4C1N2hpaWFwcDCtY/Qzavw00dzcTH19PYsWLYrZ5ty5cyxfvpz29nZCoZBuYOcRNX6aaGxsRERoaGiYOnfmzBnAepXh6NGj9PT06GsIGUJj/CTRPyi1MNF0puJL1PiKL1HjK75Eja/4EjW+4ks0nZk8/8L6XwszQSBD/S54NJ2p+BINdRRfosZXfIkaX/ElanzFl6jxFV+ixld8iRpf8SVqfMWXqPEVX/I/dytk3ZIl9qgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.plot_misclassification(X_val, y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
